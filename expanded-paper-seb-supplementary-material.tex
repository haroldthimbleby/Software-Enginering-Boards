\PassOptionsToPackage{hyphens}{url}
\documentclass{article}
\renewcommand\thesubsection{\thesection.\alph{subsection}}
%\usepackage{hyperref}
%\usepackage{refcount}
\usepackage{url}
\usepackage{doi}
\usepackage{longtable}
\usepackage{color}
\usepackage{amsmath,amssymb}
\def\httpURL#1{\href{http://#1}{\textcolor{blue}{#1}}}
\def\LONGhttpURL#1#2{\href{http://#1}{\textcolor{blue}{#2}}}

% expand paper-seb-macros.tex
% These macros allow the paper and the supplementary material to share a single sequence of bibliography citations

\DeclareUrlCommand\doi{\def\UrlLeft{{\textrm{DOI}}~}}
\DeclareUrlCommand\url{\def\UrlLeft{{\textrm{URL}}~}}
	
\renewcommand{\thefootnote}{\fnsymbol{footnote}}

\def\mytitle{Computational science: \hbox{A (fixable) failure of software~engineering}}
%Achieving professional software engineering \hbox{in scientific research}}

\def \citeeg#1{(e.g., \cite{#1})}

\def\inputifexists#1#2{\IfFileExists{#1}{\input{#1}}{\typeout{No file #1. #2}}}

% calculate percentages
\newcount \t
\newcount \tu
\def\pc#1#2{\t = #1%
\multiply \t by 100000%
\divide \t by #2% ?? 0 times percentage
\tu = \t
\divide \t by 1000% percentage, but no idea of remainder
\multiply \t by 1000% 1000 times percentage, with 00 as bottom digits
\advance \tu by -\t% bottom two digits
\divide \t by 1000\relax%
% round to nearest integer
% if ending in > .5 round up
% if ending in exactly .5 round towards nearest even number
\ifnum \tu > 500 % round up
	\advance \t by 1 
\else
	\ifnum \tu = 500 
		\ifodd \t % it's odd, so round up to even number 
			\advance \t by 1
		\else % leave rounded to even number 	
		\fi
	\fi
\fi
\the\t\%}

% insert commas into large numbers
\def\commarise#1{%[#1]
	\t=#1
    \divide \t by 1000
    \ifnum \t > 0
    	\the\t,%
    	\tu=#1
    	\multiply \t by 1000
    	\advance \tu by -\t
		\ifnum \tu < 100 0\fi
		\ifnum \tu < 10 0\fi
		\the\tu
    \else
    	#1%
    \fi
}

% simple macro to use a number register to pluralise (add an s) to words....
% \plural{\t}{fred} => \the\t\ freds if plural, or => one fred if singular
\def\plural#1#2{\ifnum #1=1 
	one #2%
\else
	\the#1\ #2s%
\fi}

% initialisBibliography <title> <starting number> <introductory text>
\newcount\bibciten \bibciten=0
\def\initialiseBibliography#1#2#3{%
	\global\def\refname{#1}
    \global\bibciten=#2
    \global\def\startBibliography{#3}
}

\def\bibskip{\vskip 1ex} % the gap between bib items generated by data.js

% read in any constants defined from the JSON data
% expand generated-constants.tex
\def\journalBreakdown{\emph{Lancet Digital Health\/} ($N=6$), \emph{Nature Digital Medicine\/} ($N=12$) and \emph{Royal Society Open Science\/} ($N=14$)}
\def\tabularJournalBreakdown{&\hbox to 3em {\hfill 6}\hskip 1em \emph{Lancet Digital Health}\\&\hbox to 3em {\hfill 12}\hskip 1em \emph{Nature Digital Medicine}\\&\hbox to 3em {\hfill 14}\hskip 1em \emph{Royal Society Open Science}\\}
\global\newcount \dataN \global\dataN=32
\global\newcount \countAuthors \global\countAuthors=264
\global\newcount \countHasBreach \global\countHasBreach=11
\global\newcount \countHasPolicy \global\countHasPolicy=26
\global\newcount \countUsesVersionControlRepository \global\countUsesVersionControlRepository=10
\global\newcount \counthasDataRepository \global\counthasDataRepository=9
\global\newcount \countNoCodeInRepo \global\countNoCodeInRepo=1
\global\newcount \numberOfJournals \global\numberOfJournals=3
\global\newcount \countCodetested \global\countCodetested=0
\global\newcount \hasDevelopedRigorously \global\hasDevelopedRigorously=0
% end expanding generated-constants.tex
% expand generated-info-for-main.tex
\newlabel{supplementary-material-makefiles}{{2}{11}{DUMMYA}{DUMMYB}{DUMMYC}}
\newlabel{on-code-data-publication}{{3}{14}{XXX}{YYYY}{ZZZZ}}
\newlabel{supplementary-Speigelhalter-section}{{4}{17}{DUMMYA}{DUMMYB}{DUMMYC}}
\def\MaxMainPaperCitationNumber{64}
\newlabel{supplementary-journal-policies-section}{{5}{25}{DUMMYA}{DUMMYB}{DUMMYC}}
\newlabel{supplementary-summary-table}{{5}{30}{DUMMY1}{DUMMY2}{DUMMY3}}
\expandafter\def \csname cite-MetricSelectionFramework\endcsname{[97]}
\expandafter\def \csname cite-PENet\endcsname{[101]}
\expandafter\def \csname cite-PostoperativeOutcomes.RiskNet\endcsname{[103]}
\expandafter\def \csname cite-philter-ucsf\endcsname{[104]}
\expandafter\def \csname cite-AI-CDSS-Cardiovascular-Silo\endcsname{[105]}
\expandafter\def \csname cite-SiameseChange\endcsname{[107]}
\expandafter\def \csname cite-dryad.1g1jwstrw\endcsname{[108]}
\expandafter\def \csname cite-rsos.192210\endcsname{[109]}
\expandafter\def \csname cite-ichHKrWj7hqlznOaR6NQVzITgp40dlqWvWAgAxyafiQ\endcsname{[110]}
\expandafter\def \csname cite-rsos.200566\endcsname{[111]}
\expandafter\def \csname cite-?view.only=87ae173f775b40d79d6cd0fdcf6d4a9c\endcsname{[112]}
\expandafter\def \csname cite-dryad.vx0k6djnr\endcsname{[115]}
\expandafter\def \csname cite-lactModel\endcsname{[116]}
\expandafter\def \csname cite-LRM\endcsname{[118]}
\expandafter\def \csname cite-1\endcsname{[119]}
\expandafter\def \csname cite-manifold-ga\endcsname{[124]}
\expandafter\def \csname cite-blast-ct\endcsname{[126]}
% end expanding generated-info-for-main.tex

\def\supplement{Supplemental Material}
% end expanding paper-seb-macros.tex

\makeatletter
      \renewcommand{\thefootnote}{\arabic{footnote}}
      {\let\oldbibcite=\bibcite
      % example: \bibcite{bad-code}{{31}{2020}{{Richards and Boudnik}}{{Richards and Boudnik}}}
      \newcount\mainNumberOfReferences \mainNumberOfReferences=0
      \def\bibcite#1#2{\global\advance\mainNumberOfReferences by 1\oldbibcite{#1}{#2}}
      % expand paper-seb-main.aux
\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\bibstyle{plos2015}
\citation{abelson}
\HyPL@Entry{0<</S/D>>}
\citation{fixit}
\citation{example-stats}
\citation{Speigelhalter}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\newlabel{problems}{{1}{2}{Introduction}{section.1}{}}
\citation{Ben,se-bias}
\citation{whitty}
\citation{assurance-case}
\@writefile{toc}{\contentsline {subsection}{\numberline {(1.a)}The role of code in science and scientific publication}{4}{subsection.1.1}\protected@file@percent }
\citation{assessing-quality}
\citation{critiques,diagnosis-reviews}
\citation{knuth}
\citation{science-review}
\citation{diagnosis-reviews}
\citation{tripod}
\citation{diagnosis-reviews}
\@writefile{toc}{\contentsline {subsection}{\numberline {(1.b)}Bugs, code and programming}{5}{subsection.1.2}\protected@file@percent }
\newlabel{knowledge}{{(1.b)}{5}{Bugs, code and programming}{subsection.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}State of the art in pandemic modeling}{5}{section.2}\protected@file@percent }
\citation{nature-summary,ICmodel}
\citation{avianFluModel,originalICmodel}
\citation{ICmodel,avianFluModel,originalICmodel}
\citation{tweet}
\citation{ferguson-interview}
\citation{basic-reproducibilty}
\citation{thumbs-up}
\citation{nature-summary,ICmodel}
\citation{codecheck,thumbs-up}
\citation{NVP}
\citation{nvp-ferguson}
\citation{refactoring}
\citation{bad-code}
\citation{pseudo}
\citation{relit}
\citation{nature-review}
\citation{nature-review}
\citation{psychological-modeling}
\citation{psychological-modeling}
\citation{actr}
\@writefile{toc}{\contentsline {subsection}{\numberline {(2.a)}Science beyond epidemiology}{7}{subsection.2.1}\protected@file@percent }
\citation{psychological-modeling}
\citation{Ben,nature-review,se-bias}
\citation{ourReview}
\citation{hamming}
\citation{NVP}
\citation{unfinished}
\citation{unfinished,lancet-unfinished}
\citation{hoare}
\citation{notebooks,popper}
\citation{machine-learning-reproducibility}
\citation{relit}
\citation{ICmodel}
\citation{ICmodel}
\citation{ICmodel}
\citation{flu-model}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Overview of peer-reviewed paper sample.\relax }}{9}{table.caption.4}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{table-overview}{{1}{9}{Overview of peer-reviewed paper sample.\relax }{table.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}A pilot survey of peer-reviewed research relying on code}{9}{section.3}\protected@file@percent }
\newlabel{survey-section}{{3}{9}{A pilot survey of peer-reviewed research relying on code}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {(3.a)}Methodology}{9}{subsection.3.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Summary of survey results.\relax }}{10}{table.caption.5}\protected@file@percent }
\newlabel{table-summary}{{2}{10}{Summary of survey results.\relax }{table.caption.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Sizes of repositories, with approximate sizes of code (in kLOC) and data for all available GitHub repositories reviewed in the survey, plus \texttt  {covid-sim} \cite  {ICmodel} for comparison. Sizes are approximate because in all repositories code and data are conceptually interchangeable (an issue explained in the Supplemental Material), so choices were made in the survey to avoid double-counting. Many repositories rely on downloading additional code and data, which is not counted in the table as the additional required material is not in the repository cited in the paper. Paper [103]\ has nothing in its repository except a single file still saying ``Code coming soon...'' despite, at the time of cloning and checking repositories, 21\ months had already elapsed since the paper referring to the code was published.\relax }}{11}{table.caption.6}\protected@file@percent }
\newlabel{table-repo-summary}{{3}{11}{Sizes of repositories, with approximate sizes of code (in kLOC) and data for all available GitHub repositories reviewed in the survey, plus \texttt {covid-sim} \cite {ICmodel} for comparison. Sizes are approximate because in all repositories code and data are conceptually interchangeable (an issue explained in the \supplement ), so choices were made in the survey to avoid double-counting. Many repositories rely on downloading additional code and data, which is not counted in the table as the additional required material is not in the repository cited in the paper. Paper \csname cite-PostoperativeOutcomes.RiskNet\endcsname \ has nothing in its repository except a single file still saying ``Code coming soon...'' despite, at the time of cloning and checking repositories, \the \pubdelayinmonths \ months had already elapsed since the paper referring to the code was published.\relax }{table.caption.6}{}}
\citation{open-source}
\citation{stability}
\@writefile{toc}{\contentsline {subsection}{\numberline {(3.b)}Summary of results}{12}{subsection.3.2}\protected@file@percent }
\citation{notebooks}
\citation{cbc}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{13}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {(4.a)}A call to action}{13}{subsection.4.1}\protected@file@percent }
\newlabel{summary}{{(4.a)}{13}{A call to action}{subsection.4.1}{}}
\citation{ethics-code}
\citation{acm-artifacts}
\citation{redmill,iec61508}
\citation{basic-reproducibilty,open-source}
\citation{ABCs-SE}
\citation{lancet-retracted}
\citation{science-lancet1,science-lancet2}
\citation{lancet-learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {(4.b)}Suggestions for further work}{15}{subsection.4.2}\protected@file@percent }
\newlabel{jvs-policy}{{(4.b)}{15}{Suggestions for further work}{subsection.4.2}{}}
\citation{jvs1}
\citation{jvs2,jvs3}
\citation{jvs1}
\citation{numerals}
\citation{fda}
\citation{tweet,ferguson-interview}
\citation{excel-fiasco}
\citation{science-delays}
\citation{whitty}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{16}{section.5}\protected@file@percent }
\citation{fixit}
\citation{reproducibility,relit,popper}
\citation{parliamentary-evidence,my-parliamentary-evidence}
\bibdata{paper-seb-main.bib}
\bibcite{abelson}{1}
\bibcite{fixit}{2}
\bibcite{example-stats}{3}
\bibcite{Speigelhalter}{4}
\bibcite{Ben}{5}
\bibcite{se-bias}{6}
\bibcite{whitty}{7}
\bibcite{assurance-case}{8}
\bibcite{assessing-quality}{9}
\citation{assessing-quality-conference}
\bibcite{critiques}{10}
\bibcite{diagnosis-reviews}{11}
\bibcite{knuth}{12}
\bibcite{science-review}{13}
\bibcite{tripod}{14}
\bibcite{nature-summary}{15}
\bibcite{ICmodel}{16}
\bibcite{avianFluModel}{17}
\bibcite{originalICmodel}{18}
\bibcite{tweet}{19}
\bibcite{ferguson-interview}{20}
\bibcite{basic-reproducibilty}{21}
\bibcite{thumbs-up}{22}
\bibcite{codecheck}{23}
\bibcite{NVP}{24}
\bibcite{nvp-ferguson}{25}
\bibcite{refactoring}{26}
\bibcite{bad-code}{27}
\bibcite{pseudo}{28}
\bibcite{relit}{29}
\bibcite{nature-review}{30}
\bibcite{psychological-modeling}{31}
\bibcite{actr}{32}
\bibcite{ourReview}{33}
\bibcite{hamming}{34}
\bibcite{unfinished}{35}
\bibcite{lancet-unfinished}{36}
\bibcite{hoare}{37}
\bibcite{notebooks}{38}
\bibcite{popper}{39}
\bibcite{machine-learning-reproducibility}{40}
\bibcite{flu-model}{41}
\bibcite{open-source}{42}
\bibcite{stability}{43}
\bibcite{cbc}{44}
\bibcite{ethics-code}{45}
\bibcite{acm-artifacts}{46}
\bibcite{redmill}{47}
\bibcite{iec61508}{48}
\bibcite{ABCs-SE}{49}
\bibcite{lancet-retracted}{50}
\bibcite{science-lancet1}{51}
\bibcite{science-lancet2}{52}
\bibcite{lancet-learning}{53}
\bibcite{jvs1}{54}
\bibcite{jvs2}{55}
\bibcite{jvs3}{56}
\bibcite{numerals}{57}
\bibcite{fda}{58}
\bibcite{excel-fiasco}{59}
\bibcite{science-delays}{60}
\bibcite{reproducibility}{61}
\bibcite{parliamentary-evidence}{62}
\bibcite{my-parliamentary-evidence}{63}
\citation{parliamentary-evidence}
\bibcite{assessing-quality-conference}{64}
\newlabel{LastPage}{{}{22}{}{page.22}{}}
\xdef\lastpage@lastpage{22}
\xdef\lastpage@lastpageHy{22}
\gdef \@abspage@last{22}
% end expanding paper-seb-main.aux
      }
\makeatother

\begin{document}

\title{\textbf{\supplement}\vskip 2ex \mytitle\vskip 2ex}

\author{Harold Thimbleby, \texttt{harold@thimbleby.net}}

%\orcid{0000-0003-2222-4243}

% To make various LaTeX processors do the right thing with page size.
\def\pprw{8.5in}
\def\pprh{11in}
\special{papersize=\pprw,\pprh}
\setlength{\paperwidth}{\pprw}
\setlength{\paperheight}{\pprh}
\setlength{\pdfpagewidth}{\pprw}
\setlength{\pdfpageheight}{\pprh}

\def\href#1{#1}

\maketitle

% this will be used to save cross references that can be used in the main paper too
\newwrite\infofile
\immediate\openout\infofile=generated-info-for-main.tex

\def\dotalph#1{\ifnum\csname c@#1\endcsname>0 .\alph{#1}\fi}

% writing to the aux file, this file generates labels like
% \newlabel{supplementary-best-practice}{{2}{5}{Software engineering best practice}{section.2}{}}
% whereas the main file using IEEEtrans class generates
% \newlabel{table-summary}{{I}{5}} or \newlabel{jvs-policy}{{V}{4}} etc

\makeatletter
\def\globalLabel#1{% we also need journal code-policies to be used in the main paper...
\immediate\write\infofile{\bslash newlabel{#1}{{\arabic{section}}{\thepage}{DUMMYA}{DUMMYB}{DUMMYC}}}
% as well as in the current document....
\immediate\write\@auxout{\string\newlabel{#1}{{\arabic{section}\dotalph{subsection}}{\thepage}{AAA}{BBB}{CCC}}}
}
\makeatother

% start supplementary material's page counters to continue on from the paper's page numbering
%\setcounterpageref{page}{LastPage}
%\addtocounter{page}{1} % otherwise we start with the same page that the main paper ended on (we want to be on the next page:-)!

\setcounter{section}{0}
\def\n#1{{\sf\bfseries ({#1})}}

\newdimen \www 
\setbox0=\hbox{\n{viii}~}
\www=\wd0 \advance \www by .4em
\def\nnInContents#1#2{\hbox to \www {\hfill\n{#1}~\hskip .4em} #2\\}

\setbox0=\hbox{\sfdefault\large(00)}
\newdimen\howwide \howwide=\wd0 \howwide=2.5em

\def\sec#1#2#3{\setbox0=\hbox{\n{#1}~~}\leftskip \wd0
%\begin{flushleft}
\subsubsection*{\setbox0=\hbox{\n{#1}~~}\hskip -\wd0\copy0 \bfseries
\immediate\write\minicontentsfile{\bslash nnInContents{#1}{#3}}%
{#2}\starredsubsectioncontents{\hbox to \howwide{\hfill (#1)} #3}}
%\end{flushleft}
\leavevmode
\vskip 1ex
\par\leftskip 0in}


\def\highlightsec#1#2#3{\sec{#1}{{#2}}{{#3}}}
\def\highlightmysubsection#1{\subsection{{#1}}\subsectioncontents{{#1}}}
\def\changemysubsection#1{\subsection{{#1}}\subsectioncontents{{#1}}}
\def\changemysection#1{\section{{#1}}\sectioncontents{{#1}}}
\def\highlightmysection#1{\section{{#1}}\sectioncontents{{#1}}}
\def\mysection#1{\section{#1}\sectioncontents{#1}}
\def\mysubsection#1{\subsection{#1}\subsectioncontents{#1}}

\makeatletter
\let \bslash = \@backslashchar
\makeatother

\def\sectioncontents#1{\immediate\write\contentsfile{\bslash contents{\arabic{section} #1}{\thepage}}}
\def\subsectioncontents#1{\immediate\write\contentsfile{\bslash subcontents{\alph{subsection}\ #1}{\thepage}}}
\def\starredsubsectioncontents#1{\immediate\write\contentsfile{\bslash subcontents{#1}{\thepage}}}

\noindent\vbox{% The table of contents
\def\contents#1#2{\vskip 0mm \noindent{\bfseries #1} \dotfill\ #2\\}
\def\subcontents#1#2{\hbox to 1em{}{#1} \dotfill\ #2\\}
\noindent
% expand generated-supplementary.toc
\contents{1 Further issues for Software Engineering Boards (SEBs)}{3}
\subcontents{a\ {Brief definition}}{3}
\subcontents{b\ Relationships of SEBs to Ethics Boards}{4}
\subcontents{c\ {SEBs are necessary but not sufficient}}{5}
\contents{2 Software engineering best practice}{5}
\subcontents{a\ Introduction and standard references}{5}
\subcontents{b\ Essential components of best practice}{6}
\subcontents{\hbox to \howwide {\hfill (0)} Requirements}{6}
\subcontents{\hbox to \howwide {\hfill (1)} {Formal methods}}{6}
\subcontents{\hbox to \howwide {\hfill (2)} Defensive programming}{8}
\subcontents{\hbox to \howwide {\hfill (3)} {Using dependable programming languages}}{8}
\subcontents{\hbox to \howwide {\hfill (4)} Open source and version control}{8}
\subcontents{\hbox to \howwide {\hfill (5)} Rigorous testing}{10}
\subcontents{\hbox to \howwide {\hfill (6)} {Good documentation and record keeping}}{10}
\subcontents{\hbox to \howwide {\hfill (7)} Usability}{11}
\subcontents{\hbox to \howwide {\hfill (8)} Reusing quality solutions}{12}
\subcontents{\hbox to \howwide {\hfill (9)} Simplicity}{12}
\subcontents{\hbox to \howwide {\hfill (10)} {Compliance with standards}}{13}
\subcontents{\hbox to \howwide {\hfill (11)} Effective multidisciplinary teamwork}{13}
\subcontents{\hbox to \howwide {\hfill (12)} {Continuous Professional Development (CPD)}}{13}
\subcontents{\hbox to \howwide {\hfill (13)} {Security and other factors}}{14}
\contents{3 Code, data and publication}{14}
\contents{4 {The Speigelhalter trustworhiness questions}}{17}
\subcontents{a\ {How trustworthy are the numbers?}}{17}
\subcontents{b\ {How trustworthy is the source?}}{18}
\subcontents{c\ {How trustworthy is the interpretation?}}{18}
\contents{5 {Summary of pilot survey}}{21}
\subcontents{a\ {Assessment criteria and methods}}{21}
\subcontents{b\ {Detecting and defending against error}}{24}
\subcontents{c\ {Code policies of sampled journals}}{25}
\subcontents{d\ {Assessments and criteria}}{26}
\subcontents{e\ {Summary of assessments}}{30}
\subcontents{f\ {References for sampled papers}}{31}
% end expanding generated-supplementary.toc
}

\newwrite\contentsfile
\immediate\openout\contentsfile=generated-supplementary.toc

\newpage
\mysection{Further issues for Software Engineering Boards (SEBs)}

\highlightmysubsection{Brief definition}
Software Engineering Boards, henceforth SEBs, will be used to help and assure that critical code, including epidemic modeling, is of high standard, to provide assurance for scientific papers, Government public health and other policies, etc, that the code used is of appropriate quality for its intended uses.  

Further details of the SEB proposal is in the main paper. Here we raise further issues for SEBs (additional to those covered in the main paper's introduction to SEBs), potential limitations and possible responses that can be addressed over time:

\begin{enumerate}\raggedright
\item 
Until there are national qualifications, nobody --- certainly nobody without professional training in software --- really knows just how bad (or good) they are at software engineering.

\item
When code is taken seriously, concerns may be raised on programmers' contributions to research, intellectual property rights, and co-authoring \cite{vancouver}. Software engineering is a hard, creative discipline, and getting epidemiological (and other scientific) models to work is generally a significant challenge, on a par with the setting up and exploring the mathematical models themselves. Often software engineers will need to explore boundary cases of models, and this typically involves hard technical mathematics \cite{hamming}. Often the software engineers will be solving entirely new problems and contributing to the research. How this is handled needs exploring. How software engineers are appropriately credited and cited for their contributions also needs exploring.

\item 
SEBs require policies on professional issues such as membership, transparency, and accountability.
 
\item
There should be a clear separation between the SEB members' activities as part of the Board, and their other activities, including professional advice, code development, or training (which is likely to be in demand from the same people who require formal approvals from the SEBs).

\item
Professional Engineering Bodies have a central role to play in professionalism, ranging from education and accreditation to providing professional structures and policies for SEBs. For example, should and if so how should the programming skills taught to computational scientists (epidemiologists, computational biologists, economists, computational chemists,~\ldots\@) be accredited?

\item
In the main paper, SEBs are viewed as a constructive contribution to good science, specifically helping improve the quality of epidemiological modeling. More generally, SEBs will have wider roles, for instance in overseeing software subject to medical device regulation \cite{fixit}.

\item
SEBs may fruitfully collaborate with other engineering disciplines to share and develop best practice. For example, engineers in other domains (e.g., civil engineers) routinely sign off projects, yet, on the other hand, they often overlook the quality of software engineering their projects implicitly rely on  --- for the same reasons as the scientific work discussed in this paper overlooks the dependence on quality software.

\item
Clearly, at least while this paper's concepts are tested and mature, SEBs will need to collaborate closely with research organizations, journals, and funding agencies in order to develop incremental developments to policies and processes that will be most effective, and which can be introduced most productively over time to the scientific community at large. Funding agencies may wish to support such strategic work, as they have previously funded one-off projects such as \cite{cosmos}.
\end{enumerate}
 
There are other ideas to help make SEBs work, but it is clear they are part of the solution. We must not let perfection be the enemy of the good. SEBs don't need to be perfect on day one, but they do need to get going in some shape or form to start making their vital contribution.

\mysubsection{Relationships of SEBs to Ethics Boards}


\begin{enumerate}\raggedright
\item 
Although SEBs may start with a checklist approach, like Ethics Boards generally do, it cannot be assumed that people approaching SEBs know enough about software engineering to perform adequate software assessments when there is any risk (as there is in public policy, medical apps, and so on). SEBs may also provide mentoring and training.

\item
Unlike Ethics Boards, which provide hands-off oversight, SEBs should provide professional advice, perhaps providing training or actually helping hands-on develop appropriately reliable software. During a pandemic SEBs would be very willing to do this, but in the long run it is not sustainable as voluntary labour, so all research, particularly medical research, should include support for professional software engineering. 

\item 
Ethics Boards typically require researchers to fill in forms and provide details, which is a feasible approach as researchers know if they are doing experiments on children, for instance, so the forms are relatively easy to fill in (if often quite tedious). On the other hand, few healthcare and medical researchers understand software and programming, so they are \emph{not\/} able to fill in useful software forms on their own. SEBs need to know how well engineered the software really is, not how good its developers \emph{think\/} it is. As typical programs are enormous, SEBs are either going to need resources to evaluate programs, or they will need to supervise independent bodies that can do it for them. 

\item
SEBs should have a two-way collaboration with Ethics Boards. 

\begin{itemize}
\item SEBs have to deal with ethical concerns, and how they may be implemented in code. One of the papers \cite{ethics-paper} in the survey (discussed later in this \supplement) is a case in point, as is the growing cross-fertilization between AI and ethics \citeeg{ai-ethics}.

\item Ethics Boards also have to deal with software, and it is clear that they often fail to do this effectively. The case of the retraction of a peer reviewed articles for \emph{The Lancet\/} \cite{science-lancet1,science-lancet2,lancet-learning} and the \emph{Journal of Vascular Surgery\/} \cite{jvs1,jvs2,jvs3}, discussed in the main paper, are cases in point.
\end{itemize}

\item
Like some Ethics Boards, SEBs might become, or be perceived as becoming, onerous and heavy handed --- as if the Board is not interested in ethics but only in following a bureaucratic pathway. It seems essential, then, that SEBs have (and perhaps are chaired by) experienced, practicing, professional software engineers to avoid this problem. 
\end{enumerate}

\changemysubsection{SEBs are necessary but not sufficient}
The main paper provides evidence and argues that SEBs (or equivalent) are necessary to help improve the quality of science, specifically science relying, explicitly or implicitly, on tools or methods based in software. 

SEBs address the problems identified at the laboratory end of doing science; they do not address the processes of review, editorial control, and action based on claimed results. As shown in the review of \plural{\dataN}{paper}, only some journals have code policies, and the policies are not enforced. In other words, improving the professionalization of software engineering has to proceed from doing science, which the paper covers, to the downstream issues of review and publication. SEBs may work with journals, funding agencies and even international standards agencies to improve broader awareness of professional software engineering, but this is a topic the present paper has not addressed. It needs doing.

\mysection{Software engineering best practice}
\label{supplementary-best-practice}
\mysubsection{Introduction and standard references}

This \supplement\ provides more explanations and justification for following standard software engineering practices that support reliable modeling, reliable research, and, most generally, reliable science. 

The reader is referred to standard textbooks for more information \citeeg{sommerville,knight}, as well as to specialized texts that are more specifically addressed to software engineering in science \citeeg{cosmos}.

The book \emph{Why Programs Fail\/} \cite{wpf} is a very good practical guide to developing better code, and will be found very accessible. Humphrey \cite{humphrey} outlines a thorough discipline for anyone wanting to become a good programmer. Improvement is such an important activity, Humphrey has also published a book to persuade managers of the benefits \cite{managers}. Further suggestions for background reading can be found throughout this section.

\mysubsection{Essential components of best practice}
Software Engineering includes the following topics, which are discussed at more length below:
\vskip 2ex

\vbox{\noindent
      % expand generated-minicontents.tex
\nnInContents{0}{Requirements}
\nnInContents{1}{{Formal methods}}
\nnInContents{2}{Defensive programming}
\nnInContents{3}{{Using dependable programming languages}}
\nnInContents{4}{Open source and version control}
\nnInContents{5}{Rigorous testing}
\nnInContents{6}{{Good documentation and record keeping}}
\nnInContents{7}{Usability}
\nnInContents{8}{Reusing quality solutions}
\nnInContents{9}{Simplicity}
\nnInContents{10}{{Compliance with standards}}
\nnInContents{11}{Effective multidisciplinary teamwork}
\nnInContents{12}{{Continuous Professional Development (CPD)}}
\nnInContents{13}{{Security and other factors}}
% end expanding generated-minicontents.tex
      }

\newwrite\minicontentsfile
\immediate\openout\minicontentsfile=generated-minicontents.tex

\sec{0}{Without defining requirements, not enough skilled effort will be put into designing and implementing reliable software --- or excess effort will be wasted}{Requirements}
It is not always necessary to program well if the code to be produced is for fun, experimenting, or for demonstrations. On the other hand, if code is intended for life-critical applications, then it is worth putting more engineering effort into it. The first step of software engineering, then, is to assess the requirements, specifically the reliability requirements of the code that is going to be produced. 

In practice, requirements and expectations change. Early experimental code, developed informally, may well be built on later to support models intended to inform public policy, for instance. Unfortunately, prototypes may impress project leaders who then want to rush into production software because, it seems, ``it obviously works.'' Fortunately, best practice software engineering can be adopted at any stage, particularly by using \emph{reverse engineering}. In reverse engineering, one carefully works out (generally partly automatically) what has already been implemented. This specification, carefully reviewed, is then used as the basis for a more rigorous software engineering process that implements a more reliable version of the system.

\highlightsec{1}{Without formal methods, there is no rigorous and checked specification of a program, so nobody --- including its developers --- will know exactly what it is supposed to do}{Formal methods}

{In the physical world, to do something as simple as design and build a barbecue, you would need to use elementary mathematics to calculate how many bricks to buy. To build something more substantial, such as block of flats, you would need to use structural engineering (with certified structural engineers) to ensure the building was safe. Although programming lends itself to mathematical analysis, it is surprising that few programmers use explicit mathematics at all in the design and implementation of software.} 

{The type and use of mathematics used in software engineering is formal methods. Not using formal methods ensures the resulting code is unsafe and unreliable. Of particular relevance to scientific modeling: there must be an explicit use of formal methods to ensure  mathematical models (such as differential equations) are correctly implemented in code (and to understand the any limitations of doing so).}

Formal methods require sophisticated knowledge of logic \cite{cbc}, as well as practical knowledge of using appropriate formal methods tools (Alloy, HOL, PVS, SPARK, and \emph{many\/} others). Using the right tools is essential for reliable programming, because the tools do quickly and reliably what, done by hand, would be slow and error-prone. Standard tools cover verification, static analysis of code, version control, documentation, and so on --- this paper explains why some of these activities are essential for reliable programming below. 

Crucially, tools are designed to catch common human errors that we are all prone to. Many tools are designed to avoid common human errors arising \emph{in the first place\/}; notably, the MISRA C toolset simply stops the developer using the most error-prone features of normal C, and hence improves the quality of programming with little effort.

Many programming languages and programming environments have integrated features that support formal methods. For example, Hoare's triples \cite{hoare} (and formal thinking based on similar ideas) are readily supported by assertions, as either provided explicitly in a programming language or through a simple API\@. In particular, assertions readily support contracts, an important rigorous way of programming: assertions allow the program, the programming language, or tools (as the case may be) to automatically (and hence rigorously) check essential details of the program. Hoare's original 1969 paper \cite{hoare} is very strongly recommended because it is a classic paper that has stood the test of time; in the 1960s it was leading research, but now it can be read as an excellent introduction, given how the field of software engineering has advanced and become more specialized and sophisticated over the decades since. Hoare is also a very good writer.

Formal methods have the huge advantage that they ``think differently'' and therefore help uncover design problems and bugs that can be found in no other way. Because formal methods are logical, mathematical theories (safety properties, and so forth) can be expressed and checked (often automatically); this provides a very high degree of insight into a program's details, and hence supports fault tolerance (e.g., redundancy). Ultimately, formal methods provides good reasons to believe the quality of the final code --- that it does what it is supposed to do. Unfortunately, because formal methods are mathematical, few programmers have experience of using them. Fortunately tools are widely available to help use formal methods very effectively.

\sec{2}{Without defensive programming, any errors --- in data, code, hardware, or in use --- will go unnoticed and be uncorrected}{Defensive programming} Defensive programming is based on a range of methods, including error checking, independent calculation (using multiple implementations written by independent programmers), assertions, regression testing, etc. Notoriously, what are often unconsciously dismissed as trivial concerns frequently lead to the hardest to diagnose errors, such as buggy handling of ``well-known, trivial'' things like numbers \cite{numerals}. The great advantage of defensive programming is that it detects, and may be able to recover from, bugs that have been missed earlier in the development process (such as typos in the code). Defensive programming requires professional training to be used effectively, for example it is not widely known that some choices of programming language make defensive programming unnecessarily hard \cite{heedless}.

A special case of defensive programming appropriate for pandemic modeling is mixing methods. Do not rely on one programming method, but mix methods (e.g., different numerical methods) to use and compare multiple approaches to the modeling.

\highlightsec{3}{Using inappropriate programming languages undermines reliability}{Using dependable programming languages}
Many popular languages are popular because they are easy to use, which is not the same as being reliable to use. The fewer constraints a language imposes, the easier it \emph{seems\/} to be to program in, but the lack of constraints means the language cannot provide the checks stricter languages do. C, for instance, which is one of the languages widely used for modeling \cite{tweet,plos}, is not a good choice for a reliable programming language --- it has many intrinsic weaknesses that are well-known to professionals, but which frequently trap inexperienced programmers. (This is not the place for a review \cite{heedless} but Excel is even worse in this regard.) In particular, C is not a portable language (unless extreme care is taken), which means models will work differently on different types of computer. SPARK Ada is one example of a much more appropriate programming language to use. SPARK Ada also has the advantage that most Ada programmers are better qualified than most C programmers.

\sec{4}{Version control and open source organizes and helps software development}{Open source and version control}
It is appreciated that the models may change and be adapted as new data and insights become available. Changing models makes it even harder to ensure that they are correct, and thus emphasizes the relevance of the core message this paper: we have to find ways to make computer models more reliable, inspectable, and verifiable. Version control keeps a record of what code was used when, and enables reconstruction of earlier versions of code that has been used. Version control is supported by many tools (such as Git, Subversion, etc). 

If version control is not used, one has no idea what the current program actually is. {Version control is essential for \emph{reproducibility\/}: \cite{basic-reproducibilty,reproducibility} it enables efforts to duplicate work to start with the exact version that was used in any published paper, provided that the published paper discloses the version and a URL for the relevant repository. Note that version control should also be used for data and web site data used by code, otherwise the results reported are not replicable.}

{If results cannot be reproduced, has anything reliable been contributed? When a modeling paper presents results from a model, it is important to reproduce those results without using the same code. Better still, research should be reproduced without sharing libraries or APIs (for example, results from a model using R might be reproduced using Mathematica --- this is a case of $N$ (where, in this case, $N=2$) version Programming \cite{NVP}). Reproducing the same results relying on the same codebase tells you little. The more independent reproductions of results the greater the evidence for belief in the implications.}

Clearly, with the transformations a program from avian flu in Thailand \cite{avianFluModel} to COVID-19 in the United States and in Great Britain \cite{ICmodel} taking place over many years, version control would have been very helpful to keep proper track of the changes. Note that professional version control repositories also provide secure off-site back up, ensuring the long-term access to the code and documentation --- this would avoid loss of \supplement\ problems, as occurred in \cite{flu-model}.

Most version control systems would, in addition, enable open source methods so the code could be shared --- and reviewed --- by a wider community. Open source is not a panacea, however; it raises many trade-offs. Particularly for world-wide concerns like pandemic modeling, it increases diversity in the software developers, and fosters a diverse scientific collaboration. Open source can raise people's standards --- some countries \cite{excel1,excel2} are using Excel models to manage COVID-19, and open source projects properly implemented would help these people enormously. 

Open source raises important licensing and management questions to ensure the quality of contributions. A salutary open source case is NPM, where lawyers from a company called Kik triggered Azer Ko\c{c}ulu, that is, a \emph{single\/} programmer, to remove all his code from a repository. This caused problems to many thousands of JavaScript programmers worldwide who could no longer compile anything --- ironically, including Kik itself \cite{npm}. 

Critically in the case of epidemic modeling, open source democratizes the model development and interpretation, and enables properly-informed public debate. Note that many (if not most) successful open source projects have had a closed team of highly dedicated and directly employed developers \cite{open-source}. 

\sec{5}{Without professional testing, there is no acceptable evidence that a program works under real conditions}{Rigorous testing}
In poorly-run software development it is very easy to miss bugs, because the flawed thinking that inserted bugs in the code is going to be the same flawed thinking with the same misconceptions that tries to detect them. Rigorous testing includes methods like fault injection. Here, the idea is that if testing finds no bugs, that may be because the testing is not rigorous enough rather than that the program actually has no bugs. Fault injection inserts random bugs, and then testing gives statistical insights into the number of bugs in a program (depending on how many deliberate bugs it successfully finds). 

It is very tempting to test code while it is being built, save some or all of the code on a repository, but forget to check that the code has not changed out of recognition of the earlier tests --- tests should be saved so that modified code can easily be tested again. For example, if a test reveals a bug, the bug should be fixed \emph{and\/} the test needs to be re-run to check the fix worked (and did not introduce other bugs previously eliminated). 

It is important that code is saved and then downloaded to a clean site, confirmed it is consistent, and a new build made (preferably by an independent tester), which is then re-tested. If this procedure (or equivalent) is not followed, there is no assurance that the code made available with the paper is complete and works reliably.

There are many other important testing methods \cite{sommerville,knight,NVP}.

\highlightsec{6}{Without documentation and record keeping, nobody --- least of all the programmer --- knows what code is supposed to do or how to get it to do it}{Good documentation and record keeping}
Documentation covers internal documentation (how code works), developer (how to include it in other programs), configuration (how to configure and compile the code in different environments), external documentation (how the code is used), and help (documentation available while using the program). 

{For critical projects, such as for pandemic modeling, all documentation (including software) should be formally controlled, typically digitally signed and backed up in secure repositories. One would also expect a structured assurance case to be made, both to help the authors understand and complete their own reasoning and to help reviewers scrutinize it \cite{assurance-case}.
}

For purely scientific purposes, perhaps the most important form of internal is internal documentation: how to understand how and why the code works. This is different from developer documentation, which is how to \emph{use\/} the code in other programs. For example, code for solving a differential equation needs explaining --- what method does it use, what assumptions does it have? In contrast, the developer documentation for differentiation would say things like it solves ordinary differential equations with parameters $e$ for the function $f$ with the independent variable $x$ in the interval $[u,v]$, or whatever, but \emph{how\/} it solves equations is of little interest to the developer who just needs to use it. How code works --- internal documentation --- is essential for the epidemiologist, or more generally any scientist. An example of a simple SIR epidemiological model's internal documentation can be found at \url{http://www.harold.thimbleby.net/sir} 

There are many tools to help manage documentation (Javadoc, Doxygen, \ldots). Literate programming is one very effective way of documenting code, and has been used for very large programming projects \cite{LP}. Literate programming has also been used directly to help publish clearer and more rigorous papers based on code \cite{relit} --- a paper that also includes a wider review of the issues.

Documentation should be supplemented by details of algorithms and proofs of correctness (or references to appropriate literature). All the documentation needs to be available to enable others to correctly download, install and correctly use a program --- and to enable them, should they wish, to repurpose it reliably for their own work. In addition, documentation requires specifications and, in turn, \emph{their\/} documentation. 

A important role of documentation is to cover configuration: how to get code to work --- without configuration, code is generally useless. The most basic is a README file, which explains how to get going; more useful approaches to configuration include make files, which are programs that do the configuration automatically.

Without proper record keeping, code becomes almost impossible to maintain if programmers leave the project. Note that computer tools can make record keeping, laboratory books etc, trivial --- if they are used.

\sec{7}{If code is not usable, even if it is ``correct'' it will not be used and interpreted correctly}{Usability}
\globalLabel{supplementary-material-makefiles}
Usability is an important consideration: \cite{hci1,hci2} is the program usable by its intended users so they can obtain correct results? Often the programmers developing code know it so well they misjudge how easy it will be for anyone else to use it --- this is a very serious problem for the lone programmer (possibly working in another country) supporting a research team. Usability is especially important when programs are to be used by other researchers and by non-programmers, including epidemiologists.

{In publishing science, an important class of user includes the scientists and others who will use or replicate the work described. When code used in research is non-trivial, it is essential that the process of successfully downloading code and configuring it to run is made as usable as possible. Typically so-called makefiles are provided, which are shell scripts or apps that run on the target machine, establish its hardware and other features, then automatically configure and compile the code to work on that machine. Makefiles typically also provide demo and test runs and other helpful features. Other approaches to improve usability are zip files, so every relevant file can be conveniently downloaded in one step, and using standard repositories, such as GitHub which allow new forks to be made, and so on.}

\sec{8}{Without using existing solutions (libraries, APIs, etc) reinventing code merely reinvents bugs}{Reusing quality solutions}
Reusing quality code (mathematical functions, database operations, user interface features, connectivity, etc) avoids having to develop it oneself, saves time and avoids the risks of introducing new bugs. The more code that is reused, the more likely many people will have contributed to improving it --- for example, reusing a standard database package will provide Atomicity, Consistency, Isolation, and Durability (so-called ACID properties) without any further work (nor even needing to understanding what useful guarantees these basic properties ensure). 

Note that reusing code assumes the originators of the code followed good software engineering practice --- particularly including good documentation; equally, if the code being developed building on it follows good software engineering practice, it too can be shared and further improved as it gets more exposure. Its quality improves through having scrutiny by the wider community, and in successful cases, leading to consensus on the best methods. Indeed, reuse, scrutiny, and consensus are the foundations of good science.

Anticipating reuse during program development is called \emph{flexibility}, where various programming techniques can greatly enhance the ease and reliability of reuse \cite{flexibility}.

A special case of reuse is to use software tools to help with software development. The tools (if appropriately chosen) have been carefully developed and widely tested. Tools enable software developers to avoid or solve complex programming problems (including maintenance) repeatedly and with ease.

\sec{9}{Poor programmers often fix bugs rather than the causes of bugs: complexity and obfuscation}{Simplicity} 
When a program doesn't quite do what is wanted, it is tempting to add more features or variables, or to treat the problem as an ``exception'' and program around it --- which inserts more code and, almost certainly, more bugs. This way lies over-fitting, a problem familiar from statistics (and machine learning). Programs can be made over-complex and they can then do anything; an over-complex program may seem correct by accident. Instead, the hallmarks of good science are that of parsimony and simplicity; if a simple program can do what is needed it is more likely to be correct. A simpler program is easier to prove correct, easier to program, and easier to debug. A special case of needing simplicity is when fixing bugs: instead of fixing bugs one at a time, one should be fixing the \emph{reasons\/} why the bugs have happened. Generally, when bugs are fixed, programmers should determine \emph{why\/} the bugs occurred, and thence repair the program more strategically.


\highlightsec{10}{International standards have been developed to support critical software development}{Compliance with standards}

To ensure adherence to best practice and, importantly, to avoid being unaware of relevant methodologies, professional software development projects adopt and adhere to relevant standards, such as ISO/IEC/IEEE 90003:2018 \cite{iso}. However, for safety-critical models or models of national policy significance, much stronger standards such as aviation software standards, such as RTCA DO-178C/EUROCAE ED-12C \cite{178C}, commonly called DO-178C, will be more appropriate. Publications should then cite the  standards to which their computer models comply. 

Note that medical device regulation, which has its own standards, is lagging behind professional software engineering practice, and currently provides no useful guidance for critical software development \cite{fixit}.

\sec{11}{Effective multidisciplinary teamwork is essential because no individual has the capacity to develop non-trivial reliable software}{Effective multidisciplinary teamwork}

As this long list illustrates, Software Engineering is a complex and wide-ranging subject. Software engineering cannot be done effectively by individuals working alone (for instance, code review is impossible for individuals to perform effectively), even without considering the complexities of the domain the code is intended for (in the present case, including pandemic modeling, mathematical modeling, public health policy, etc). Multidisciplinary teamwork is essential.

Modern software is complex, and no one person can have the skills to understand all relevant aspects of all but the most trivial of programs. Furthermore, programming is a cognitively demanding task, and causes loss of situational awareness (that is, cognitive ``overload'' making one unable to track requirements beyond those thought to be directly related to the specific task in hand). The main solution to both problems is teamwork, to bring fresh insights, different mindsets and skills to the task.
 
Peer review of code is an essential teamwork practice in reliable program development: \cite{peerReview,knight} it is easy to make programming mistakes that one is unaware of, and an independent peer review process is required to help identify such unnoticed errors. 

Almost all software will be used by other people, and user interface design is the field concerned with developing usable and effective software. A fundamental component of user interface design is working with users and user testing: without engaging users, developers are very likely to introduce quirks that make systems less usable (often less safe) than they should be. In short, users have to be brought into the software team too.

\highlightsec{12}{Computing technologies are advancing rapidly, and best practice in software engineering is continually evolving}{Continuous Professional Development (CPD)}

As computing technology continues to develop rapidly --- especially as new programming tools and systems are introduced --- best practice in software engineering is also rapidly evolving. Continuous Professional Development (CPD) is essential. 

Ironically, the more organized CPD the more likely the content itself will lag behind. There is an argument for two-way links between universities (and other research organizations), research science developers, including enabling developers to undertake part-time research degrees. Research degrees teach not just current best-practice but also how to stay abreast of the relevant technologies and literature as it develops.

The UK's Software Sustainability Institute is one initiative that is making important contributions \cite{ssi-report,ssi-url}, and its web site will no doubt remain timely and up to date in a way that this paper cannot.

Note that CPD is not just a matter of learning current best practice, but a continual process as best practice itself continually evolves. {In software engineering, a current (as of 2021) initiative concerns reproducible code artifacts and badging papers to clearly show the approaches they take \cite{acm-artifacts}, and this will in due course have a direct impact on software engineering standards in other fields.}

\highlightsec{13}{Other factors \ldots}{Security and other factors}
Of course, there are many other factors to be considered for the professional development of critical code, such as using appropriate methods to ensure cybersecurity \cite{security-engineering,cyber-cacm}, particularly while also being able to up- and download secure updates.

For pandemic modeling specifically, understanding the limitations of numerical methods (in particular, how numerical methods are affected by the choice of programming language and style of programming) is critical.\footnote{{For example \cite{example-numerical-error} was noticed to use literal numbers at too high a precision for the chosen language, where conformant implementations use IEEE 754 double precision 64-bit floating point. Such an error typically has an undefined impact on results, and unfortunately is easy to overlook as the program almost certainly ignores the error when running.}} Hamming \cite{hamming} is considered a classic, but there is a huge choice available.

{For reasons of space, the present paper does not discuss the issues raised by AI, nor the many very important, non-trivial social and professional concerns, which have complex implications for software engineering practice, such as managing programming teams, data ethics, privacy, legal liability \cite{Schneier}, or software as a matter in law, as in disputes over model results or disputes over ownership of code \cite{electronic-evidence}.}

\mysection{Code, data and publication}
\immediate\write\infofile{\bslash newlabel{on-code-data-publication}{{\arabic{section}}{\thepage}{XXX}{YYYY}{ZZZZ}}}

There is no fundamental difference between code and data, and no distinction that is relevant for scientific publication purposes. There is no distinction one can imagine that cannot easily, even accidentally, be circumvented. In other words, a journal's data policies and code policies should be the identical --- and the conventionally stricter data policies should also apply to code. It is baffling that some journals have data policies that are weaker than their data policies; it is certainly indefensible to have no code policies at all.

{Significant cyber-vulnerabilities result from there being no difference between code and data. For example: an email arrives, which brings data to a user. The user opens an attachment, perhaps a word processor text document, which is more data. The word processor runs macros in the text document --- but now it is code. The macros move data onto the user's disc. The data there then runs as code, and corrupts the user's data across the disc --- which includes both data and code stored in files. And so on. Each step of a computer virus infection crosses over non-existent ``boundaries'' between data and code \cite{viruses}.}

This section's discussion may sound like arcane and irrelevant pedantry, but these issues are at the very foundations of Computer Science.\footnote{{Many of the foundational issues were explored thoroughly by Christopher Strachey and others in the 1960s; Strachey's classic lectures are reprinted in an accessible 2000 publication \cite{strachey}. Being originally a very old paper this classic introduction is much easier to read than many more recent discussions of the foundations of Computer Science.}} If we ignore or misunderstand these basic things --- or overlook them in policies and procedures --- bugs are the inevitable (and confusing) consequence.

The main paper points out that data is often embedded in code as ``magic numbers.'' Let's now explain how. 

A fragment of program code might say

\begin{center}\texttt{x = 324.9+sin(theta*pi/2);}\end{center}

This is clearly all source code, but the number 324.9 above is likely to be some sort of relevant data, though it might be a physical constant whose value does not depend at all on \emph{this\/} experiment. The next hard-coded value mentioned in the calculation is difficult to categorize: is the value of $\pi$ empirical data or is it part of a standard formula? Historically, even $\pi$ was definitely an empirical value, but today it is a mathematical constant --- except in experiments to determine its value empirically. The point is, the distinctions between data, program and even mathematical constants are purely a matter of perspective.

Unfortunately, there is data that is extremely easy to overlook (and therefore is very hard to manage). You may assume that the function \texttt{sin}, as used in the calculation example above, is the standard trigonometric function for calculating sines (and because of $\pi$, you assume it is taking radians as the parameter type) but almost all programming languages allow \texttt{sin} to be any function whatsoever. Confusingly, it is generally a different function when the code is run on a different computer.

It is impossible to tell. More complex code will often have many facts ``hard wired'' into the code --- so in fact the code contains data. Code can even read in formulas from data and compile them to perform further calculations, and so on. Equally, data can control the flow of code. For example, data summarizing patients may include their gender, but the program processes males and females differently. Then data starts becoming like code. 

{Many computer programs blur the distinctions deliberately, to create virtual machines. Data is then run on the virtual machine as program. Many programs provide standard features to do this, such as LISP's and JavaScript's \texttt{eval} functions. Henderson's book \cite{henderson} builds an elegant Pascal program to run \emph{any\/} LISP program as data, and then shows that the LISP program can run itself running other programs, so it is now its own code and \emph{its\/} data --- despite being purely data to the Pascal program. There are numerous advantages to doing this, including: the Pascal program is not just reading data, but structured data that must conform to the rules of LISP; the LISP running itself runs faster than the original Pascal running LISP, even though the Pascal virtual machine is still doing it in the recursive case; LISP is a much more powerful language than Pascal, so a virtual machine can be used to escape the barriers of a limited implementation such as Pascal. In short, any distinctions between code and data are impossible to maintain.}

In the present paper, we knowingly built on this blur between data and code. However, what we did was not unusual except in our explicit and rigorous approach to managing and summarizing data reliably in the paper.

The paper and its \supplement\ are typeset in \LaTeX, a popular typesetting language. \LaTeX\ not only has text (as you are reading right now) but it also has code. For example, ``\LaTeX'' was typeset by running the code for a macro called \verb|\LaTeX|, which then calculated how to position the letters as they are wanted. When $\pi$ was written above, the code that generated what you read actually said \verb|$\pi$| --- so is this data that just says $\pi$ or is it code that tells the computer to change character sets from Latin to Greek, and then uses \verb|\pi| as a program variable name to select a particular glyph from the data about typesetting Greek characters? The distinctions are all a bit moot. In other words, the publication itself is data to a \LaTeX\ program, and within that data it includes further programs. Indeed, \LaTeX\ is run on a virtual machine, in exactly the same way that Henderson's LISP is, and doing so provides the same advantages.

The data for this paper's survey was itself originally written as literal text in \LaTeX: it meant that \LaTeX\ could process it to produce a typeset table (as in the \supplement\ above). As the extent of the data grew, it rapidly became apparent that \LaTeX\ is a poor choice to manage structured data. A simple JavaScript program was written to convert the \LaTeX\ data into JSON (which is much more readable than \LaTeX) and also generate CSV files that can be processed in standard office software such as Excel, which some readers may prefer. In fact, examining and comparing the same data in the contrasting formats, this typeset file, in JSON, and in Excel (reading the generated CSV) provided multiple different perspectives of the data that increased redundancy and confidence that the data was correct and correctly handled. 

{It is important to note that using such techniques is quite routine in science publication, though often pre-existing tools are used to streamline the process (and to ensure that it is more widely understood). The paper \cite{paper-usesRMarkdown}, for example, in addition to using a typesetting system for publication, also placed its code in a repository using R Markdown \cite{RMarkdown}, a programming environment based on R designed for generating and documenting lab books --- almost the polar opposite of \LaTeX, which is designed for publication but can be used for programming.}

Finally note that what may look like magic numbers used throughout the present paper (such as the $\the\dataN$, as in ``\plural{\dataN}{paper} were evaluated'') are all in fact named, calculated and placed \emph{in situ\/} directly from computations performed on the JSON paper's data.

\changemysection{The Speigelhalter trustworhiness questions}
\globalLabel{supplementary-Speigelhalter-section}

David Speigelhalter is concerned how statistics is often misused and misunderstood. In his \emph{The Art of Statistics\/} \cite{Speigelhalter} Speigelhalter brings together his advice for making reliable statistical claims: they need to be accessible, intelligible, assessable, and usable --- the claims need to be properly accountable. Speigelhalter proposes ten questions to ask when confronted with any claim based on statistical evidence. Some of his questions are quite general, and might be applied to any sort of scientific claims, but all have analogous questions that could be addressed to software code or papers relying on code --- analogues are suggested in \textbf{bold} below. 

What might seem like dauntingly technical software issues are no more demanding than the basic statistical issues that are regularly acceded to; failing to ask them is as risky as dismissing statistical scrutiny.

\def\questionsection#1{\changemysubsection{#1}}
\def\question#1{\item \emph{#1\/}}
\def\sequestion#1{\begin{itemize}\raggedright\item[$\blacktriangleright$] \textbf{#1}\end{itemize}}

\questionsection{How trustworthy are the numbers?}
\newcounter{resumeCounter}

\begin{enumerate}
\question{How rigorously has the study been done?} For example, check for `internal validity,' appropriate design and wording of questions, pre-registration of the protocol, take a representative sample, using randomization, and making a fair comparison with a control group.

\sequestion{How rigorously has the software engineering been done? Section \ref{supplementary-best-practice} in the \supplement\ provides a list of important issues that must be addressed for any reliable software.}

\sequestion{``Internal validity'' assumes that there is evidence the programmers had uncertainty in the code's reliability and checked it. Were different methods used and compared, or was all confidence put into a single implementation? What internal consistency checks does the implementation have? Were invariants and assertions defined and checked? }

\question{What is the statistical uncertainty/confidence in the findings?} Check margins of error, confidence intervals, statistical significance, multiple comparisons, systemic bias.

\sequestion{How are the claims presented that give us confidence in the code that they are based on? Are there discussions of invariants, independent checks for errors, and so on? Again, \supplement\ section \ref{supplementary-best-practice} provides further discussion of such issues.}


\question{Is the summary appropriate?} Check appropriate use of averages, variability, relative and absolute risks.

\sequestion{If the claims are exploratory, weaker standards of coding can be used; if the claims are a basis for critical decisions, then there should be evidence of using appropriate software engineering (such as defensive programming) to provide appropriate confidence in the results claimed.}
\setcounter{resumeCounter}{\value{enumi}}
\end{enumerate}
\questionsection{How trustworthy is the source?}
\begin{enumerate}
\setcounter{enumi}{\value{resumeCounter}}
\question{How reliable is the source of the story?} Consider the possibility of a biased source with conflicts of interest, and check publication is independently peer-reviewed. Ask yourself, `Why does this source want me to hear this story?'

\sequestion{The source of many science stories is the output of running some code. How reliable is this code? What evidence is there that the code was well-engineered so its reliability can be trusted?}

\question{Is the story being spun?} Be aware of the use of framing, emotional appeal through quoting anecdotes about extreme cases, misleading graphs, exaggerated headlines, big-sounding numbers.

\sequestion{Be wary of AI and ML which may have been trained by chance or specifically (if not deliberately) to get the results described.}

\question{What am I not being told?} This is perhaps the most important question of all. Think about cherry-picked results, missing information that would conflict with the story, and lack of independent comment.

\sequestion{Cherry picking with code is often unconscious and is very common: when running code produces the ``cherries'' for a paper it is tempting to stop testing the code and just assume it is running correctly. So, what evidence is there that the code was rigorously developed and cherry picking avoided?}

\setcounter{resumeCounter}{\value{enumi}}
\end{enumerate}
\questionsection{How trustworthy is the interpretation?}
\begin{enumerate}
\setcounter{enumi}{\value{resumeCounter}}
\question{How does the claim fit with what else is known?} Consider the context, appropriate comparators, including historical data, and what other studies have shown, ideally in a meta-analysis.

\sequestion{Is there any discussion of the code and how does it compare with other peer-reviewed publications using code used for similar purposes?}

\question{What's the claimed explanation for what has been seen?} Vital issues are correlation v.\ causation, regression to the mean, inappropriate claim that a non-significant result means `no effect,' confounding attribution, prosecutor's fallacy.

\sequestion{These are all good statistical questions. The software engineering analogy is: are the claims backed up by a sufficiently detailed discussion of the algorithms and software engineering that justify the appropriateness of the chosen software implementation? The \supplement\ list in section \ref{supplementary-best-practice} provides examples of expected explanations for the trustworthiness of running some code.}

\question{How relevant to the story is the audience?} Think about generalizability, whether the people being studied are special case, has there been an extrapolation from mice to people.

\sequestion{Generalizability is equivalent to is the code available, easy to understand and use for more general purposes --- including further work and checking the reproducibility of the claims being made?}

\question{Is the claimed effect important?} Check whether the magnitude of the effect is practically significant, and be especially wary of claims of `increased risk.'
\end{enumerate}

\newcount\temporary \temporary=\mainNumberOfReferences
\newcount\temporaryPlusOne \temporaryPlusOne=\temporary
\advance \temporaryPlusOne by 1

\bibliographystyle{plos2015}

\global \newdimen \shortercol 
\renewenvironment{thebibliography}[1]{%
	\section*{\uppercase{\refname}}
    \startBibliography
    \raggedright
    \parindent=0em
    \setbox0=\hbox{\hskip 1ex[#1]}
    \labelwidth=\wd0
    \advance \labelwidth by 1ex
    \shortercol=\columnwidth \advance \shortercol by -\labelwidth
}{}

\makeatletter    
    \renewcommand{\bibitem}[2][DEFAULT]{%
    	\if@filesw \immediate\write\@auxout{\string\bibcite{#2}{{{\the\bibciten}{}{{}}{{}}}}}\fi
        \parshape 2 0em \columnwidth \labelwidth \shortercol
        \leavevmode\hbox to \labelwidth{\hfill[\the\bibciten]\hskip 1ex}%
        \global\advance\bibciten by 1
        \ignorespaces 
    }
\makeatother

\initialiseBibliography{Additional references for \supplement}{\temporaryPlusOne}{References numbered 1--\the\temporary\ appear in the reference list in the main paper.}

\immediate\write\infofile{\bslash def\bslash MaxMainPaperCitationNumber{\the\temporary}}

% expand bibliography paper-seb-supplementary-material.bbl
\begin{thebibliography}{10}

\bibitem{vancouver}
{Vancouver Group}.
\newblock Uniform requirements for manuscripts submitted to biomedical
  journals.
\newblock JAMA. 1997;277(11):927--934.
\newblock doi:{10.1001/jama.1997.03540350077040}.

\bibitem{cosmos}
Stepney S, Polack FAC, Alden K, Andrews PS, Bown JL, Droop A, et~al.
\newblock Engineering Simulations as Scientific Instruments: A Pattern
  Language.
\newblock Springer; 2018.

\bibitem{ai-ethics}
Misselhorn C.
\newblock Artificial Morality. {Concepts}, Issues and Challenges.
\newblock Social Science and Public Policy. 2018;55:161--169.
\newblock doi:{10.1007/s12115-018-0229-y}.

\bibitem{sommerville}
Sommerville I.
\newblock Software Engineering.
\newblock 10th ed. Pearson; 2015.

\bibitem{knight}
Knight J.
\newblock Fundamentals of Dependable Computing for Software Engineers.
\newblock CRC Press; 2012.

\bibitem{wpf}
Zeller A.
\newblock Why Programs Fail: A Guide to Systematic Debugging.
\newblock Morgan Kaufmann; 2006.

\bibitem{humphrey}
Humphrey WS.
\newblock PSP: A Self-Improvement Process for Software Engineers.
\newblock Addison Wesley; 2005.

\bibitem{managers}
Humphrey WS.
\newblock Winning with Software: An Executive Strategy.
\newblock Addison-Wesley Professional; 2001.

\bibitem{heedless}
Thimbleby H.
\newblock Heedless Programming: Ignoring Detectable Error is a Widespread
  Hazard.
\newblock Software --- Practice {\&} Experience. 2012;42(11):1393--1407.
\newblock doi:{10.1002/spe.1141}.

\bibitem{plos}
Chao DL, Halloran ME, Obenchain VJ, {Longini Jr} IM.
\newblock FluTE, a Publicly Available Stochastic Influenza Epidemic Simulation
  Model.
\newblock PLOS Computational Biology. 2010;6(1):e1000656.
\newblock doi:{10.1371/journal.pcbi.1000656}.

\bibitem{excel1}
Abir M, Nelson C, Chan EW, Al-Ibrahim H, Cutter C, Patel K, et~al.
\newblock RAND Critical Care Surge Response Tool: An Excel-Based Model for
  Helping Hospitals Respond to the COVID-19 Crisis.
\newblock RAND Corporation; 2020.
\newblock Available from: \url{www.rand.org/pubs/tools/TLA164-1.html}.

\bibitem{excel2}
Alvarez NM, Gonzalez-Gonzalez E, Trujillo-de Santiago G.
\newblock Modeling {COVID-19} epidemics in an Excel spreadsheet:
  {Democratizing} the access to first-hand accurate predictions of epidemic
  outbreaks.
\newblock MedRxiv. 2020;doi:{10.1101/2020.03.23.20041590}.

\bibitem{npm}
Schlueter IZ.
\newblock Blog: kik, left-pad, and npm.
\newblock NPM Blog; 23 March 2016.
\newblock Available from:
  \url{blog.npmjs.org/post/141577284765/kik-left-pad-and-npm}.

\bibitem{LP}
Knuth DE.
\newblock Literate programming. vol.~27.
\newblock Center for the Study of Language and Information Publication Lecture
  Notes; 1992.

\bibitem{hci1}
Shneiderman B, Plaisant C, Cohen M, {\emph{et al}}.
\newblock Designing the User Interface: Strategies for Effective Human-Computer
  Interaction.
\newblock 6th ed. Pearson; 2016.
\newblock Available from: \url{www.cs.umd.edu/hcil/DTUI6}.

\bibitem{hci2}
Thimbleby H.
\newblock Press On: Principles of Interaction Programming.
\newblock MIT Press; 2007.

\bibitem{flexibility}
Hanson C, Sussman GJ.
\newblock Software design for flexibility: How to avoid programming yourself
  into a corner.
\newblock MIT Press; 2021.

\bibitem{iso}
{ISO/IEC JTC 1/SC 7 Software and systems engineering Committees}.
\newblock Software engineering --- Guidelines for the application of ISO
  9001:2015 to computer software.
\newblock International Organization for Standardization (ISO); 2015.
\newblock Available from: \url{www.iso.org/standard/74348.html}.

\bibitem{178C}
{RTCA Committee SC-205}.
\newblock DO-178C --- Software Considerations in Airborne Systems and Equipment
  Certification.
\newblock RTCA; 2011.
\newblock Available from: \url{my.rtca.org/NC__Product?id=a1B36000001IcmqEAC}.

\bibitem{peerReview}
Baum T, {Le\ss mann} H, Schneider K.
\newblock The Choice of Code Review Process: A Survey on the State of the
  Practice.
\newblock In: Lecture Notes in Computer Science. vol. 10611 of Product-Focused
  Software Process Improvement: 18th International Conference; 2017. p.
  111--127.

\bibitem{ssi-report}
Brett A, Croucher M, Haines R, Hettrick S, Hetherington J, Stillwell M, et~al.
\newblock State of the Nation Report for Research Software Engineers.
\newblock Research Software Engineer Network; 2017.
\newblock Available from: \url{zenodo.org/record/495360#.Xyfuyi2ZOCM}.

\bibitem{ssi-url}
{Software Sustainability Institute}. Web site; 2020.
\newblock Available from: \url{software.ac.uk}.

\bibitem{security-engineering}
Anderson R.
\newblock Security Engineering.
\newblock 3rd ed. Wiley; 2020.

\bibitem{cyber-cacm}
Shostack A, Zurko ME.
\newblock Secure Development Tools and Techniques Need More Research That Will
  Increase Their Impact and Effectiveness in Practice.
\newblock Communications of the ACM. 2020;63(5):39--41.
\newblock doi:{10.1145/3386908}.

\bibitem{Schneier}
Schneier B.
\newblock Click Here To Kill Everybody --- Security and Survival in a
  Hyper-connected World.
\newblock W. W. Norton {\&} Company, Inc; 2018.

\bibitem{electronic-evidence}
Mason S, Seng D.
\newblock Electronic Evidence.
\newblock 4th ed. Humanities Digital Library; 2017.

\bibitem{viruses}
Thimbleby H, Anderson SO, Cairns P.
\newblock A Framework for Modelling Trojans and Computer Virus Infection.
\newblock Computer Journal. 1999;41(7):444--458.
\newblock doi:{10.1093/comjnl/41.7.444}.

\bibitem{strachey}
Strachey C.
\newblock Fundamental Concepts in Programming Languages.
\newblock Higher-Order and Symbolic Computation. 2000;13:11--49.
\newblock doi:{10.1023/A:1010000313106}.

\bibitem{henderson}
Henderson P.
\newblock Functional Programming: Application and Implementation.
\newblock Computer Science. Prentice-Hall International; 1980.

\bibitem{RMarkdown}
Xie Y, Allaire JJ, Grolemund G.
\newblock R Markdown: The Definitive Guide.
\newblock Chapman {\&} Hall/CRC; 2020.

\bibitem{RS-policy}
Hurst P. The Royal Society -- Data sharing and mining; 2022.

\end{thebibliography}

% end expanding bibliography paper-seb-supplementary-material.bbl


\highlightmysection{Summary of pilot survey}
\label{data-methods-section}
\highlightmysubsection{Assessment criteria and methods}\label{data-methods-subsection}
A survey sampled of recent papers that were published online in July 2020, accepted for publication after peer review in \the\numberOfJournals\ high-profile, highly competitive leading peer-reviewed journals, namely \journalBreakdown. Papers were selected from the journals' July 2020 new online listings where the paper's title implied that code had been used in the research. Commentary, correspondence and editorials were excluded. The sample represents what the editorial and the broader peer review community considers to be good practice. 

The selection process will have certainly missed some papers that use code, but the criterion selects papers where the wording of the title indicates that the authors consider code to be a component of the scientific contribution. Indeed, all sampled papers used code in their research.  Although there is unavoidable subjectivity in the paper evaluations and uncontrolled bias from using a single evaluator (the author of this paper), it is hoped that using a sample of \plural{\dataN}{paper} from \plural{\numberOfJournals}{diverse journal} is sufficient to randomize errors so that they largely cancel out, and the overall trends as discussed in this paper are reliable. It should be noted that, except where a paper provides a URL to a code repository, much code was disorganized so possibly not all code was reviewed because it was too hard to find (some emails to authors have not been responded to). 
 
Since almost every scientific paper relies on generic computer code (calculating statistics, plotting graphs, storing and manipulating data, accessing internet resources, etc), the baseline of papers using code was not assessed. Papers whose title indicated their contribution included or relied on bespoke code were selected, and all those clearly relied heavily on their own specifically developed code. Papers that may have relied on bespoke code but whose titles made no such implication were not assessed.

There is considerable debate over what good commenting practice is, but this is because comments have many roles --- from helping students to get marks in assessments, asserting intellectual rights, reminding the developer of things to do, managing version control, to explaining the code to third parties. Different programming languages also develop ``cultures'' that encourage different approaches for comments (examples include R Markdown, Mathematica Notebooks, JavaDoc, Haskell's Haddock, and so on). For scientific code, however, the explanatory role is critical, and this is what was assessed in this survey. Note that comments used for explanation does not preclude any other uses.

The completeness or executability of code was not assessed, although if code was obviously incomplete this was noted. Whether code runs as claimed is a matter of research integrity, which is beyond the scope of this survey. What is relevant to the study is whether the code is described in sufficient detail that the methods used can be scrutinized. Obviously being able to run the code will help, but clarity in documentation and comments is critical. It is more like ``can we see the critical pages from your lab book so we understand what you did?'' rather than ``can we have free run of your laboratory?''

As an informal survey, intended to establish whether the issues in epidemic modeling were more widespread, and given the very poor level of documentation found in scientific code, it was not felt necessary to have independent or blind assessment.

The data was recorded in JSON (JavaScript Object Notation), which is a simple standard data format. A typical entry in the data file looks like this (with long field values truncated for clarity):

% expand generated-example-data.tex
\def\countFields{30}
\noindent\texttt{
\hspace*{2em}\{\hspace*{2em}\newline
\hspace*{4em} accessed: "14 July 2020",\newline
\hspace*{4em} doubleChecked: "17 January 2021",\newline
\hspace*{4em} authors: "Callahan A, Steinberg E, Fries JA, Gomba \ldots,\newline
\hspace*{4em} year: 2020,\newline
\hspace*{4em} title: "Estimating the efficacy of symptom-based \ldots,\newline
\hspace*{4em} volume: 3,\newline
\hspace*{4em} number: 95,\newline
\hspace*{4em} journal: "Nature Digital Medicine",\newline
\hspace*{4em} doi: "10.1038/s41746-020-0300-0",\newline
\hspace*{4em} dataComment: "On request",\newline
\hspace*{4em} hasCodeInPrinciple: 1,\newline
\hspace*{4em} codeComment: "``Code is available upon request from th \ldots,\newline
\hspace*{4em} pages: 3\newline
\hspace*{2em}\}
}
% end expanding generated-example-data.tex

The data was written out by hand, after reading and reviewing each paper in the survey. In total there are \countFields\ data fields available for documenting papers, but not all need be used for each paper; for example, the field \texttt{hasCodeTested} defaults to \texttt{false}, so it need not be set --- it is also an error to set it if another field asserts there is no code to evaluate! (A separate JSON data structure maps the data fields to English descriptions, along with default values if they are optional descriptors.)

A JavaScript program sanity checks the JSON data. The sanity checks found a few errors (e.g., it checks that if there are comments of any sort then there must be some accessible code; it checks the DOI is accessible, etc), which led to a productive double-checking of all the facts of the original papers --- and correcting all the errors. Some papers that had had no code available during the first assessment had uploaded code by the time of the double-checking.\footnote{{Note that double-checking was performed by the same person as the first assessment, though with the benefit of a six month gap to bring a degree of independence}.} A field \texttt{doubleChecked} was added to supplement the original data field \texttt{accessed} to track the process of double-checking the data; the sanity checks then of course checked all \texttt{doubleChecked} fields were completed.

Note that since JSON data is JavaScript code, it was convenient to combine the data, the data sanity checking, and the analysis all in a single file. Hence, running the data generates the core human-readable information used in this paper.

The JavaScript data+program generates files from the JSON, with all the definitions; these files were then included in both the main paper and in this \supplement, so when the paper or \supplement\ is typeset all tables and specific data items are typeset automatically, consistently and reliably by \LaTeX\@.\footnote{Because of its approach to automatic typesetting, this journal requires that no files are explicitly \texttt{input} into \LaTeX, so a simple JavaScript program is used to recursively expand all \texttt{input} commands before submission. If the source files are available for download after this paper is accepted, they will therefore contain no \texttt{input} commands, but they will contain comments at the appropriate points in the expanded source code explaining the sources of the \texttt{input} data.} For example, the register \texttt{\bslash dataN} is set to the value \the\dataN, which is the total number of papers assessed in the JSON data, and the macro \texttt{\bslash journalBreakdown} is defined directly from the data to be the following text (when typeset in \LaTeX):

\begin{quote}
\journalBreakdown 
\end{quote}

--- which is the breakdown of the total $N=\the\dataN$ by journal name. The \emph{exact\/} same text was also used in the main paper. 

An interesting consequence of this automatic approach is that as the author found themselves starting to write text such as:

\begin{quote}
\tt Code repositories were used by \plural{\countUsesVersionControlRepository}{paper} \ldots
\end{quote}

it motivated extending the JavaScript data processing so that \emph{all\/} specific quantities mentioned in the paper are traceable directly back to the JSON data. The phrase above is now in fact written in \LaTeX\ in the paper as follows:

\begin{quote}\tt\small
Code repositories were used by \\
\bslash plural\{\bslash countUsesVersionControlRepository\}\{paper\} \ldots
\end{quote}

where {\tt\small \bslash plural} automatically writes a word (``paper'' in this case) in singular or plural form as required (in this case, the variable \texttt{countUsesVersionControlRepository} = \the\countUsesVersionControlRepository). When typeset the text above is generated with the relevant number or numbers inserted from the JSON data. 

Some of the files generated from the JSON data are Unix shell scripts. For example, details of all the papers with GitHub repositories are automatically collected into a shell script so the repositories can be cloned locally and then measured to generate table \ref{table-repo-summary}, as used in the main paper.

The full JavaScript JSON data and processing code (including the makefile) is provided in this paper's repository, as described in the main paper.

\highlightmysubsection{Detecting and defending against error}
\label{detecting-against-error}
It must be emphasized that an automatically-guaranteed same number appearing in multiple different contexts is an extremely effective way of defending against common Human Factors errors. 

% check it works for other numbers 
%\countUsesVersionControlRepository=296

Normally, when we write \the\countUsesVersionControlRepository\ in a paper, we proof read it as ``just a number'' and the sentence would likely seem to make as much sense if the number was 
\newcount\t
\t=\countUsesVersionControlRepository
\divide \t by 10
\newcount\fraction
\fraction=\countUsesVersionControlRepository
\newcount\tent \tent=\t \multiply \tent by 10
\advance\fraction by -\tent
\the\t.\the\fraction,
\t=\countUsesVersionControlRepository
\advance \t by -1
\the\t,
\t=\countUsesVersionControlRepository
\advance \t by 1
\the\t, or
\t=\countUsesVersionControlRepository
\multiply \t by 10
\the\t\ --- we hardly bother to pay attention because we know what we are reading; at least we know what we meant to write. It is very hard to spot one's own typos. 

\begin{itemize}\raggedright
\item
The first and last errors above are examples of the very common error of ``out by ten'' (common partly because the correct number, \the\countUsesVersionControlRepository\ looks very similar to \t=\countUsesVersionControlRepository
\divide \t by 10
\the\t.\the\fraction, and \the\countUsesVersionControlRepository.0 also looks very similar to 
\t=\countUsesVersionControlRepository
\multiply \t by 10
\the\t) \cite{fixit}. 

\item
The middle two errors above are examples of the common error of ``out by one,'' or ``fence post errors'' frequently made by mixing up counting fences or the posts (there is usually one more post than fence panel) \cite{fixit}.
\end{itemize}

All the discussion and examples above were generated automatically, and have been checked  correct for other base values than \the\countUsesVersionControlRepository. This approach, too, considerably helps defend against common Human Factors errors. For example, if we set \texttt{\bslash countUsesVersionControlRepository}=\the\countUsesVersionControlRepository\ to be 2348, say, then all of the sentences say something unexpected and so have to be more carefully proof-read, significantly reducing confirmation bias.

If any of the numbers used in a paper were safety critical (e.g., lives directly depend on their correct values) then further checks would have been made to help detect and avoid errors. For example, \LaTeX\ makes it very easy to check that numbers fall within reasonable ranges, or have any other required safety properties. For the present paper, a potential problem is that the paper is typeset \emph{before\/} the JSON data has been analyzed; in which case, none of the variables, like \texttt{\bslash countUsesVersionControlRepository}, will have been correctly set and their values could be undefined or nonsense.

\newcount\min \min=5
\newcount\max \max=20
%\countUsesVersionControlRepository=4
\ifnum \countUsesVersionControlRepository>\max countUsesVersionControlRepository is far too large! \fi
\ifnum \countUsesVersionControlRepository<\min countUsesVersionControlRepository is far too small! \fi
\ifnum \countUsesVersionControlRepository>\max
	\else 
		\ifnum \countUsesVersionControlRepository<\min
			\else
								\textbf{This is \emph{automatic\/} confirmation that $$\the\min \leq \mbox{\tt countUsesVersionControlRepository} \leq \the\max$$ and therefore falls within pre-defined sanity limits for this paper.}
		\fi
\fi

The corresponding error messages would not normally be printed in a paper like this --- they would normally be reported by stopping a \LaTeX\ run, that is before the paper can be distributed and cause confusion.

\highlightmysubsection{Code policies of sampled journals}
\globalLabel{supplementary-journal-policies-section}

It is noteworthy that none of the journals sampled permit any reliable style of managing data in published papers, such as described above in section \ref{detecting-against-error}. In particular, for all the papers that had accessible code, the code included explicit (and relevant) data that was not archived \emph{as\/} data in the journal repositories.
\\

\newdimen\tabwidth
\tabwidth=\textwidth
\advance \tabwidth by -4em
\def\specifyurl{\vskip 3mm
\begingroup\raggedleft\scriptsize
} 
\def\specifyurletc#1{\endgroup\\
\hbox{ }\hfill\begin{tabular}{|p{\tabwidth}@{}}
#1
\end{tabular}\vskip .3cm
}

{\sf
\noindent\textbf{Extract from \emph{Royal Society Open Science\/} author guidelines} \\
--- It is a condition of publication that authors make the primary data, materials (such as statistical tools, protocols, software) and code publicly available. These must be provided at the point of submission for our Editors and reviewers for peer-review, and then made publicly available at acceptance. [\ldots] As a minimum, sufficient information and data are required to allow others to replicate all study findings reported in the article. Data and code should be deposited in a form that will allow maximum reuse. As part of our open data policy, we ask that data and code are hosted in a public, recognized repository, with an open licence (CC0 or CC-BY) clearly visible on the landing page of your dataset.}

\specifyurl
\url{royalsociety.org/journals/authors/author-guidelines/#data}
\specifyurletc{Accessed 29 July 2020; the policy has been revised (undated, but accessed 2 February 2022) but retains the same principles; full policy now available via a DOI \cite{RS-policy}. The policy still retains an emphasis on data accessibility, and continues a lack of awareness that code and data are equivalent and often mixed (see section \ref{on-code-data-publication}).}

\noindent\textbf{Extract from \emph{Nature Digital Medicine\/} author guidelines}\\
{\sf --- A condition of publication in a Nature Research journal is that authors are required to make materials, data, code, and associated protocols promptly available to readers without undue qualifications. [\ldots] A condition of publication in a Nature Research journal is that authors are required to make unique materials promptly available to others without undue qualifications.}

\specifyurl
\url{www.nature.com/nature-research/editorial-policies/reporting-standards#availability-of-data}
\specifyurletc{Accessed 29 July 2020; since updated to require [in part] ``Upon publication, Nature Portfolio journals consider it best practice to release custom computer code in a way that allows readers to repeat the published results. Code should be deposited in a DOI-minting repository such as Zenodo, Gigantum or Code Ocean and cited in the reference list following the guidelines described here.'' (accessed 2 February 2022).
}

\noindent\textbf{\emph{Lancet Digital Health\/} author guidelines}\\
Journal has detailed data policies, but no code policy.

\specifyurl
\url{marlin-prod.literatumonline.com/pb-assets/Lancet/authors/tldh-info-for-authors.pdf}
\specifyurletc{Accessed 29 July 2020. Still no code policy (accessed 2 February 2022).}

\noindent\textbf{Extract from \emph{Journal of Vascular Surgery\/} author guidelines}\\
Journal has detailed data policies, but no code policy. While no \emph{Journal of Vascular Surgery\/} papers were surveyed, the following statement on data policies is relevant for section \ref{jvs-policy} in the main paper:

\vskip 3mm \noindent {\sf --- The authors are required to produce the data on which the manuscript is based for examination by the Editors or their assignees, should they request it. [\ldots] The authors should consider including a footnote in the manuscript indicating their willingness to make the original data available to other investigators through electronic media to permit alternative analysis and/or inclusion in a meta-analysis.}
\specifyurl
\url{www.editorialmanager.com/jvs/account/JVS_Instructions%20for%20Authors2020.pdf}
\specifyurletc{Accessed 29 July 2020. Policy unchanged when accessed 2 February 2022.}

\highlightmysubsection{Assessments and criteria}

\def\flagStyle#1{\textcolor{red}{\sf #1}}

Legend:\\
% expand generated-legend.tex
\begin{tabular}{lp{4.5in}}
\flagStyle{$\sf P_c$}&Journal has a code policy (see section~\ref{supplementary-journal-policies-section})\\
\flagStyle{$\sf P_{{\mbox{\scriptsize c-breach}}}$}&Paper breaches journal code policy (see section~\ref{supplementary-journal-policies-section})\\
\flagStyle{$\sf R_c$}&Paper uses a code repository (e.g., GitHub)\\
\flagStyle{$\sf R_{\mbox{\scriptsize c-empty}}$}&Code repository contains no code\\
\flagStyle{$\sf R_d$}&Paper uses a data repository (e.g., Dryad, Figshare, GitHub)\\
\flagStyle{$\sf S_{\mbox{\scriptsize NONE}}$}&No code available at all (note: code is not expected for standard models, systems or statistical methods)\\
\flagStyle{$\sf S_p$}&Paper says source code is available in principle\\
\flagStyle{$\sf S_{+}$}&Paper or URL provides source code\\
\flagStyle{$\sf S_{{\mbox{\scriptsize rigorous}}}$}&Evidence that source code was developed rigorously\\
\flagStyle{$\sf S_{\mbox{\scriptsize tested}}$}&Evidence that source code has been run with a clean build and tested\\
\flagStyle{$\sf S_{{\mbox{\scriptsize otherSE}}}$}&Other evidence of good practice; see details in summary table\\
\flagStyle{$\sf C_0$}&Code has no non-trivial comments\\
\flagStyle{$\sf C_1$}&Code only has trivial comments (e.g., copyright)\\
\flagStyle{$\sf C_2$}&Helpful comments explaining code intent, rather than rephrasing the code\\
\flagStyle{$\sf C_{+}$}&Code has substantial, useful comments and documentation\\
\end{tabular}
% end expanding generated-legend.tex

\newpage

{
\def\citenum#1{\cite{#1}}
\begin{longtable}{@{}cp{2.25in}p{2.25in}@{}}
\sf\bfseries Ref&\sf\bfseries Data&\sf\bfseries Code \\ \hline \endhead 
% expand generated-assessments.tex
\citenum{ref-1} & On request\flagStyle{ } & ``Code is available upon request from the corresponding author'' (requested)\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf S_p$\hskip 3pt{}}\\
\citenum{ref-2} & ``The datasets used in the current study are available from the corresponding author upon reasonable request and under consideration of the ethical regulations''\flagStyle{ $\sf R_d$\hskip 3pt{}} & Matlab. Documented overview, but only trivial comments\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf R_c$\hskip 3pt{}$\sf S_{+}$\hskip 3pt{}$\sf C_1$\hskip 3pt{}}\\
\citenum{ref-3} & ``In accordance with Twitter policies of data sharing, data used in the generation of the algorithm for this study will not be made publicly available''\flagStyle{ } & ``Due to the sensitive and potentially stigmatizing nature of this tool, code used for algorithm generation or implementation on individual Twitter profiles will not be made publicly available''\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf P_{{\mbox{\scriptsize c-breach}}}$\hskip 3pt{}$\sf S_{\mbox{\scriptsize NONE}}$\hskip 3pt{}}\\
\citenum{ref-4} & ``The datasets generated during and/or analyzed during the current study are available from the corresponding author on reasonable request.''``''\flagStyle{ } & ``This code would be made available upon reasonable request.'' (requested)\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf S_p$\hskip 3pt{}}\\
\citenum{ref-5} & Nothing available\flagStyle{ } & Nothing available (despite building two voice-based virtual counselors)\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf P_{{\mbox{\scriptsize c-breach}}}$\hskip 3pt{}$\sf S_{\mbox{\scriptsize NONE}}$\hskip 3pt{}}\\
\citenum{ref-6} & ``The datasets generated and analyzed during the study are not currently publicly available due to HIPAA compliance agreement but are available from the corresponding author on reasonable request''\flagStyle{ } & Poor commenting, no documentation\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf R_c$\hskip 3pt{}$\sf S_{+}$\hskip 3pt{}$\sf C_1$\hskip 3pt{}}\\
\citenum{ref-7} & ``The dataset generated and analyzed for this study will not be made publicly available due to patient privacy and lack of informed consent to allow sharing of patient data outside of the research team''\flagStyle{ } & No code available\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf P_{{\mbox{\scriptsize c-breach}}}$\hskip 3pt{}$\sf S_{\mbox{\scriptsize NONE}}$\hskip 3pt{}}\\
\citenum{ref-8} & ``The datasets generated during and/or analyzed during the current study are not publicly available due to institutional restrictions on data sharing and privacy concerns. However, the data are available from the corresponding author on reasonable request''\flagStyle{ } & Empty GitHub repository: ``Code coming soon\ldots'' it says\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf P_{{\mbox{\scriptsize c-breach}}}$\hskip 3pt{}$\sf R_c$\hskip 3pt{}$\sf R_{\mbox{\scriptsize c-empty}}$\hskip 3pt{}$\sf S_{\mbox{\scriptsize NONE}}$\hskip 3pt{}}\\
\citenum{ref-9} & ``The i2b2 data that support the findings of this study are available from i2b2 but restrictions apply to the availability of these data, which require signed safe usage and research-only. Data from UCSF are not available at this time as they have not been legally certified as being De-Identified, however, this process is underway and the data may be available by the time of publication by contacting the authors. Requesters identity as researchers will need to be confirmed, safe usage guarantees will need to be signed, and other restrictions may apply''\flagStyle{ } & Basic documentation, very little comment\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf R_c$\hskip 3pt{}$\sf S_{+}$\hskip 3pt{}$\sf C_1$\hskip 3pt{}}\\
\citenum{ref-10} & ``Not available due to restrictions in the ethical permit, but may be available on request''\flagStyle{ } & Trivial comments, no documentation\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf R_c$\hskip 3pt{}$\sf S_{+}$\hskip 3pt{}$\sf C_1$\hskip 3pt{}}\\
\citenum{ref-11} & ``The data that support the findings of this study are available in a deidentified form from Cleveland Clinic, but restrictions apply to the availability of these data, which were used under Cleveland Clinic data policies for the current study, and so are not publicly available''\flagStyle{ } & ``We used only free and open-source software'' some of which is unspecified\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf P_{{\mbox{\scriptsize c-breach}}}$\hskip 3pt{}$\sf S_{\mbox{\scriptsize NONE}}$\hskip 3pt{}}\\
\citenum{ref-12} & ``The i-ROP cohort study data for ROP is not publicly available due to patient privacy restrictions, though potential collaborators are directed to contact the study investigators \ldots''\flagStyle{ } & Not all code on GitHub, minor comments\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf R_c$\hskip 3pt{}$\sf S_{+}$\hskip 3pt{}$\sf C_1$\hskip 3pt{}}\\
\citenum{paper-usesRMarkdown} & Data available on Dryad\flagStyle{ $\sf R_d$\hskip 3pt{}} & Code and example runs available in R Markdown\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf S_{+}$\hskip 3pt{}$\sf C_{+}$\hskip 3pt{}}\\
\citenum{ref-14} & Data directly written into program code\flagStyle{ } & Basic Matlab with routine comments\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf P_{{\mbox{\scriptsize c-breach}}}$\hskip 3pt{}$\sf S_{+}$\hskip 3pt{}$\sf C_1$\hskip 3pt{}}\\
\citenum{ref-15} & Data available on Dryad plus publicly available data from the 1000 genomes project. Currently (apparently) for private view\flagStyle{ $\sf R_d$\hskip 3pt{}} & Code available for private view, though some code available with minor comments. Paper describes using two contrasting methods to help confirm correctness\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf S_p$\hskip 3pt{}$\sf S_{{\mbox{\scriptsize otherSE}}}$\hskip 3pt{}$\sf C_2$\hskip 3pt{}}\\
\citenum{ref-16} & Data available on Dryad\flagStyle{ $\sf R_d$\hskip 3pt{}} & Reasonaby commented code on Dryad, but code is not complete and presumably never checked\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf S_p$\hskip 3pt{}$\sf C_2$\hskip 3pt{}}\\
\citenum{ref-17} & On request\flagStyle{ } & R lightly commented\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf S_p$\hskip 3pt{}$\sf C_1$\hskip 3pt{}}\\
\citenum{ethics-paper} & No data required\flagStyle{ } & Unrunnable incomplete code fragment\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf P_{{\mbox{\scriptsize c-breach}}}$\hskip 3pt{}$\sf S_p$\hskip 3pt{}}\\
\citenum{ref-19} & Data embedded in PDF\flagStyle{ } & No code available\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf P_{{\mbox{\scriptsize c-breach}}}$\hskip 3pt{}$\sf S_{\mbox{\scriptsize NONE}}$\hskip 3pt{}}\\
\citenum{ref-20} & Data available on Dryad\flagStyle{ $\sf R_d$\hskip 3pt{}} & Some comments, some code in Matlab\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf S_p$\hskip 3pt{}$\sf C_2$\hskip 3pt{}}\\
\citenum{ref-21} & Partial data on Dryad\flagStyle{ $\sf R_d$\hskip 3pt{}} & Documented R, including manual\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf R_c$\hskip 3pt{}$\sf S_{+}$\hskip 3pt{}$\sf C_{+}$\hskip 3pt{}}\\
\citenum{ref-22} & No data required\flagStyle{ } & ``We constructed a bioeconomic model for an RSSF [restricted fishing effort small-scale fishery] using game theory'' for which results are discussed, yet no code is available\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf P_{{\mbox{\scriptsize c-breach}}}$\hskip 3pt{}$\sf S_{\mbox{\scriptsize NONE}}$\hskip 3pt{}}\\
\citenum{ref-23} & Data cited, not all available\flagStyle{ } & Trivial documentation\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf R_c$\hskip 3pt{}$\sf S_{+}$\hskip 3pt{}$\sf C_1$\hskip 3pt{}}\\
\citenum{example-numerical-error} & On Figshare\flagStyle{ $\sf R_d$\hskip 3pt{}} & On Figshare, large amount of disorganised and undocumented code. Helpful features to make usable for third parties\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf S_{+}$\hskip 3pt{}$\sf C_1$\hskip 3pt{}}\\
\citenum{ref-25} & Data on Dryad\flagStyle{ $\sf R_d$\hskip 3pt{}} & No code available\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf P_{{\mbox{\scriptsize c-breach}}}$\hskip 3pt{}$\sf S_{\mbox{\scriptsize NONE}}$\hskip 3pt{}}\\
\citenum{ref-26} & Data on various web sites\flagStyle{ } & No code available\flagStyle{ $\sf P_c$\hskip 3pt{}$\sf P_{{\mbox{\scriptsize c-breach}}}$\hskip 3pt{}$\sf S_{\mbox{\scriptsize NONE}}$\hskip 3pt{}}\\
\citenum{ref-27} & Data on request\flagStyle{ } & ``The coding used to train the artificial intelligence model are dependent on annotation, infrastructure, and hardware, so cannot be released.'' (!) Algorithm (not source code) available on request.\flagStyle{ $\sf S_{\mbox{\scriptsize NONE}}$\hskip 3pt{}}\\
\citenum{ref-28} & Data on request\flagStyle{ } & Python scripts can be requested\flagStyle{ $\sf S_p$\hskip 3pt{}}\\
\citenum{ref-29} & Unspecified location on large website requiring registration\flagStyle{ $\sf R_d$\hskip 3pt{}} & Has overall documentation but poorly commented Matlab code on GitHub\flagStyle{ $\sf R_c$\hskip 3pt{}$\sf S_{+}$\hskip 3pt{}$\sf C_1$\hskip 3pt{}}\\
\citenum{ref-30} & Available to researchers who meet criteria for access to confidential data\flagStyle{ } & Despite the paper being a ``deep learning algorithm'' the code is not available\flagStyle{ $\sf S_{\mbox{\scriptsize NONE}}$\hskip 3pt{}}\\
\citenum{ref-31} & Data access conditional on approved study proposal\flagStyle{ } & Almost completely uncommented Python, but does have a basic setup script\flagStyle{ $\sf R_c$\hskip 3pt{}$\sf S_{+}$\hskip 3pt{}$\sf C_0$\hskip 3pt{}}\\
\citenum{ref-32} & Unspecified locations on several large websites\flagStyle{ } & Python used and apparently GitHub, but --- an oversight? --- no code is available\flagStyle{ $\sf S_{\mbox{\scriptsize NONE}}$\hskip 3pt{}}\\
% end expanding generated-assessments.tex
\end{longtable}
}

\highlightmysubsection{Summary of assessments}

\immediate\write\infofile{\bslash newlabel{supplementary-summary-table}{{\arabic{section}}{\thepage}{DUMMY1}{DUMMY2}{DUMMY3}}}

\begin{center}
% expand generated-summary-table.tex
\begin{tabular}{|rrrc|}\hline
Number of papers sampled relying on code&32&100\%&\\\hline\hline
\multicolumn{4}{|l|}{\textbf{Access to code}}\\
Have some or all code available&12&38\%&\\
Some or all code in principle available on request&8&25\%&\\
No code available&12&38\%&\\\hline
\multicolumn{4}{|l|}{{\textbf{Evidence of basic good software engineering practice}}}\\
{Evidence program designed rigorously}&{0}&{0\%}&\\
{Evidence source code properly tested}&{0}&{0\%}&\\
{Other methods, e.g., independent coding methods}&{1}&{3\%}&\\\hline
\multicolumn{4}{|l|}{\textbf{Documentation and comments}}\\
Substantial code documentation and comments&2&6\%&\\
Comments explain some code intent&3&9\%&\\
Procedural comments (e.g., author, date, copyright)&10&31\%&\\
No usable comments&17&53\%&\\\hline
\multicolumn{4}{|l|}{\textbf{Repository use}}\\
Code repository (e.g., GitHub) --- 1 was empty&10&31\%&\\
Data repository (e.g., Dryad or GitHub)&9&28\%&\\\hline
\multicolumn{4}{|l|}{\textbf{Adherence to journal code policy (if any)}}\\
Papers published in journals with code policies&26&81\%&\\
Clear breaches of code policy (if any) & 11&42\%&($N=26$)\\
\hline\end{tabular}
% end expanding generated-summary-table.tex
\end{center}

This is exactly the same table as table \ref{table-summary} from the main paper, reproduced here for convenience. See section \ref{data-methods-section}.\ref{data-methods-subsection} in this \supplement\ for details of the process that generated it.

\stepcounter{subsection}
\def\reftitle{References for sampled papers}
\def\unnumberedrefname{{\reftitle}}
\renewcommand\refname{\subsectioncounter\ {\unnumberedrefname}}

\initialiseBibliography{{\alph{subsection} \reftitle}}{\the\bibciten}{} 

\begin{thebibliography}{999}
\subsectioncontents{\unnumberedrefname}
\raggedright

% horrible hack -- we want to refer to surveyed papers in the main body, but only in the
% figure summarising github repos, so we do it specially....

\def\maprepo#1{\immediate\write\infofile{\bslash expandafter\bslash def \bslash csname cite-#1\bslash endcsname{[\the\bibciten]}}}

% expand generated-supplementary-references.tex
\vbox{\bibitem{ref-1}
Callahan A,  Steinberg E,  Fries JA,  Gombar S,  Patel B,  Corbin CK and  Shah NH, ``Estimating the efficacy of symptom-based screening for COVID-19,'' \emph{Nature Digital Medicine}, \textbf{3}(95):3pp, 2020. DOI \texttt{10.1038/s41746-020-0300-0}\\\hfill{Accessed 14 July 2020.}\ {Double-checked 17 January 2021}.}\bibskip

\vbox{\maprepo{MetricSelectionFramework}\bibitem{ref-2}
Kanzler CM,  Rinderknecht MD,  Schwarz A,  Lamers I,  Gagnon C,  Held JPO,  Feys P,  Luft AR,  Gassert R and  Lambercy O, ``A data-driven framework for selecting and validating digital health metrics: use-case in neurological sensorimotor impairments,'' \emph{Nature Digital Medicine}, \textbf{3}(80):17pp, 2020. DOI \texttt{10.1038/s41746-020-0286-7} {Code \url{github.com/ChristophKanzler/MetricSelectionFramework}}\\\hfill{Accessed 14 July 2020.}\ {Double-checked 17 January 2021}.}\bibskip

\vbox{\bibitem{ref-3}
Roy A,  Nikolitch K,  McGinn R,  Jinah S,  Klement W and  Kaminsky ZA, ``A machine learning approach predicts future risk to suicidal ideation from social media data,'' \emph{Nature Digital Medicine}, \textbf{3}(78):12pp, 2020. DOI \texttt{10.1038/s41746-020-0287-6}\\\hfill{Accessed 14 July 2020.}\ {Double-checked 17 January 2021}.}\bibskip

\vbox{\bibitem{ref-4}
Levine DM,  Co Z,  Newmark LP,  Groisser AR,  Holmgren AJ,  Haas JA and  Bates DW, ``Design and testing of a mobile health application rating tool,'' \emph{Nature Digital Medicine}, \textbf{3}(74):7pp, 2020. DOI \texttt{10.1038/s41746-020-0268-9}\\\hfill{Accessed 14 July 2020.}\ {Double-checked 17 January 2021}.}\bibskip

\vbox{\bibitem{ref-5}
Kannampallil T,  Smyth JM,  Jones S,  Payne PRO and  Ma J, ``Cognitive plausibility in voice-based AI health counselors,'' \emph{Nature Digital Medicine}, \textbf{3}(72):4pp, 2020. DOI \texttt{10.1038/s41746-020-0278-7}\\\hfill{Accessed 14 July 2020.}\ {Double-checked 17 January 2021}.}\bibskip

\vbox{\maprepo{PENet}\bibitem{ref-6}
Huang S,  Kothari T,  Banerjee I,   Chute C,  Ball RL,  Borus N,  Huang A,  Patel BN,  Rajpurkar P,  Irvin J,  Dunnmon J,   Bledsoe J,  Shpanskaya K,  Dhaliwal A,  Zamanian R,  Ng AY and  Lungren MP, ``PENet a scalable deep-learning model for automated diagnosis of pulmonary embolism using volumetric CT imaging,'' \emph{Nature Digital Medicine}, \textbf{3}(61):9pp, 2020. DOI \texttt{10.1038/s41746-020-0266-y} {Code \url{github.com/marshuang80/PENet}}\\\hfill{Accessed 14 July 2020.}\ {Double-checked 17 January 2021}.}\bibskip

\vbox{\bibitem{ref-7}
Dhruva SS,  Ross JS,  Akar JG,   Caldwell B,  Childers K,  Chow W,  Ciaccio L,  Coplan P,  Dong J,  Dykhoff HJ,  Johnston S,  Kellogg T,  Long C,  Noseworthy PA,  Roberts K,  Saha A,  Yoo A and  Shah ND, ``Aggregating multiple real-world data sources using a patient-centered health-data-sharing platform,'' \emph{Nature Digital Medicine}, \textbf{3}(60):9pp, 2020. DOI \texttt{10.1038/s41746-020-0265-z}\\\hfill{Accessed 14 July 2020.}\ {Double-checked 17 January 2021}.}\bibskip

\vbox{\maprepo{PostoperativeOutcomes.RiskNet}\bibitem{ref-8}
Hofer IS,  Lee C,  Gabel E,  Baldi P and  Cannesson M, ``Development and validation of a deep neural network model to predict postoperative mortality, acute kidney injury, and reintubation using a single feature set,'' \emph{Nature Digital Medicine}, \textbf{3}(58):10pp, 2020. DOI \texttt{10.1038/s41746-020-0248-0} {Code \url{github.com/cklee219/PostoperativeOutcomes_RiskNet}}\\\hfill{Accessed 14 July 2020.}\ {Double-checked 17 January 2021}.}\bibskip

\vbox{\maprepo{philter-ucsf}\bibitem{ref-9}
Norgeot B,  Muenzen K,  Peterson TA,  Fan X,  Glicksberg BS,  Schenk G,  Rutenberg E,  Oskotsky B,  Sirota M,  Yazdany J,  Schmajuk G,  Ludwig D,  Goldstein T and  Butte AJ, ``Protected Health Information filter (Philter): accurately and securely de-identifying free-text clinical notes,'' \emph{Nature Digital Medicine}, \textbf{3}(57):8pp, 2020. DOI \texttt{10.1038/s41746-020-0258-y} {Code \url{github.com/BCHSI/philter-ucsf}}\\\hfill{Accessed 14 July 2020.}\ {Double-checked 17 January 2021}.}\bibskip

\vbox{\maprepo{AI-CDSS-Cardiovascular-Silo}\bibitem{ref-10}
Choi D,  Park JJ,  Ali T and  Lee S, ``Artificial intelligence for the diagnosis of heart failure,'' \emph{Nature Digital Medicine}, \textbf{3}(54):6pp, 2020. DOI \texttt{10.1038/s41746-020-0261-3} {Code \url{github.com/ubiquitous-computing-lab/AI-CDSS-Cardiovascular-Silo}}\\\hfill{Accessed 14 July 2020.}\ {Double-checked 17 January 2021}.}\bibskip

\vbox{\bibitem{ref-11}
Hilton CB,  Milinovich A,  Felix C,  Vakharia N,   Crone T,   Donovan C,  Proctor A and  Nazha A, ``Personalized predictions of patient outcomes during and after hospitalization using artificial intelligence,'' \emph{Nature Digital Medicine}, \textbf{3}(51):8pp, 2020. DOI \texttt{10.1038/s41746-020-0249-z}\\\hfill{Accessed 14 July 2020.}\ {Double-checked 17 January 2021}.}\bibskip

\vbox{\maprepo{SiameseChange}\bibitem{ref-12}
Li MD,  Chang K,  Bearce B,  Chang BY,  Huang AJ,  Campbell JP,  Brown JM,  Singh P,  Hoebel KV,   Erdo{\u g}mu\c{s} D,  Ioannidis S,  Palmer W,  Chiang MF and  Kalpathy-Cramer J, ``Siamese neural networks for continuous disease severity evaluation and change detection in medical imaging,'' \emph{Nature Digital Medicine}, \textbf{3}(48):9pp, 2020. DOI \texttt{10.1038/s41746-020-0255-1} {Code \url{github.com/QTIM-Lab/SiameseChange}}\\\hfill{Accessed 14 July 2020.}\ {Double-checked 19 January 2021}.}\bibskip

\vbox{\maprepo{dryad.1g1jwstrw}\bibitem{paper-usesRMarkdown}
Hoffman JI,  Nagel R,  Litzke V,  Wells DA and  Amos W, ``Genetic analysis of \emph{Boletus edulis\/} suggests that intra-specific competition may reduce local genetic diversity as a woodland ages,'' \emph{Royal Society Open Science}, \textbf{7}(200419):13pp, 2020. DOI \texttt{10.1098/rsos.200419} {Code \url{datadryad.org/stash/dataset/doi:10.5061/dryad.1g1jwstrw}}\\\hfill{Accessed 22 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\maprepo{rsos.192210}\bibitem{ref-14}
Gr\"onquist P,  Panchadcharam P,  Wood D,  Menges A,  R\"uggeberg M and  Wittel FK, ``Computational analysis of hygromorphic self-shaping wood gridshell structures,'' \emph{Royal Society Open Science}, \textbf{7}(192210):9pp, 2020. DOI \texttt{10.1098/rsos.192210} {Code \url{royalsocietypublishing.org/doi/suppl/10.1098/rsos.192210}}\\\hfill{Accessed 22 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\maprepo{ichHKrWj7hqlznOaR6NQVzITgp40dlqWvWAgAxyafiQ}\bibitem{ref-15}
Amos W, ``Signals interpreted as archaic introgression appear to be driven primarily by faster evolution in Africa,'' \emph{Royal Society Open Science}, \textbf{7}(191900):9pp, 2020. DOI \texttt{10.1098/rsos.191900} {Code \url{datadryad.org/stash/share/ichHKrWj7hqlznOaR6NQVzITgp40dlqWvWAgAxyafiQ}}\\\hfill{Accessed 22 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\maprepo{rsos.200566}\bibitem{ref-16}
Gordon M,  Viganola D,  Bishop M,  Chen Y,  Dreber A,  Goldfedder B,  Holzmeister F,  Johannesson M,  Liu Y,  Twardy C,  Wang J and  Pfeiffer T, ``Are replication rates the same across academic fields? Community forecasts from the DARPA SCORE programme,'' \emph{Royal Society Open Science}, \textbf{7}(200566):7pp, 2020. DOI \texttt{10.1098/rsos.200566} {Code \url{royalsocietypublishing.org/doi/suppl/10.1098/rsos.200566}}\\\hfill{Accessed 22 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\maprepo{?view.only=87ae173f775b40d79d6cd0fdcf6d4a9c}\bibitem{ref-17}
Evans D and  Field AP, ``Predictors of mathematical attainment trajectories across the primary-to-secondary education transition: parental factors and the home environment,'' \emph{Royal Society Open Science}, \textbf{7}(200422):20pp, 2020. DOI \texttt{10.1098/rsos.200422} {Code \url{osf.io/a5xsz/?view_only=87ae173f775b40d79d6cd0fdcf6d4a9c}}\\\hfill{Accessed 22 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\bibitem{ethics-paper}
Beale N,  Battey H,  Davison AC and  MacKay RS, ``An unethical optimization principle,'' \emph{Royal Society Open Science}, \textbf{7}(200462):11pp, 2020. DOI \texttt{10.1098/rsos.200462}\\\hfill{Accessed 22 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\bibitem{ref-19}
Cherevko AA,  Gologush TS,  Petrenko IA,  Ostapenko VV and  Panarin VA, ``Modelling of the arteriovenous malformation embolization optimal scenario,'' \emph{Royal Society Open Science}, \textbf{7}(191992):16pp, 2020. DOI \texttt{10.1098/rsos.191992}\\\hfill{Accessed 22 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\maprepo{dryad.vx0k6djnr}\bibitem{ref-20}
Soczawa-Stronczyk AA and  Bocian M, ``Gait coordination in overground walking with a virtual reality avatar,'' \emph{Royal Society Open Science}, \textbf{7}(200622):19pp, 2020. DOI \texttt{10.1098/rsos.200622} {Code \url{datadryad.org/stash/dataset/doi:10.5061/dryad.vx0k6djnr}}\\\hfill{Accessed 22 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\maprepo{lactModel}\bibitem{ref-21}
Duruz S,  Vajana E,  Burren A,  Flury C and  Joost S, ``Big dairy data to unravel effects of environmental, physiological and morphological factors on milk production of mountain-pastured Braunvieh cows,'' \emph{Royal Society Open Science}, \textbf{7}(200638):13pp, 2020. DOI \texttt{10.1098/rsos.200638} {Code \url{github.com/SolangeD/lactModel}}\\\hfill{Accessed 22 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\bibitem{ref-22}
de Azevedo EZD,  Dantas DV and  Daura-Jorge FG, ``Risk tolerance and control perception in a game-theoretic bioeconomic model for small-scale fisheries,'' \emph{Royal Society Open Science}, \textbf{7}(200621):11pp, 2020. DOI \texttt{10.1098/rsos.200621}\\\hfill{Accessed 22 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\maprepo{LRM}\bibitem{ref-23}
Abdolhosseini-Qomi AM,  Jafari SH,  Taghizadeh A,  Yazdani N,  Asadpour M and  Rahgozar M, ``Link prediction in real-world multiplex networks via layer reconstruction method,'' \emph{Royal Society Open Science}, \textbf{7}(191928):22pp, 2020. DOI \texttt{10.1098/rsos.191928} {Code \url{github.com/UT-NSG/LRM}}\\\hfill{Accessed 22 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\maprepo{1}\bibitem{example-numerical-error}
Webster J and  Amos M, ``A Turing test for crowds,'' \emph{Royal Society Open Science}, \textbf{7}(200307):12pp, 2020. DOI \texttt{10.1098/rsos.200307} {Code \url{figshare.com/collections/Supplementary_information_for_Webster_J_and_Amos_M_A_Turing_Test_for_Crowds_/4859118/1}}\\\hfill{Accessed 22 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\bibitem{ref-25}
Zhu Y-l,  Wang C-J,  Gao F,  Xiao Z-x,  Zhao P-l and  Wang J-y, ``Calculation on surface energy and electronic properties of CoS${}_2$,'' \emph{Royal Society Open Science}, \textbf{7}(191653):12pp, 2020. DOI \texttt{10.1098/rsos.191653}\\\hfill{Accessed 22 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\bibitem{ref-26}
Yu B,  Scott CJ,  Xue X,  Yue X and  Dou X, ``Derivation of global ionospheric Sporadic E critical frequency ($f_o$Es) data from the amplitude variations in GPS/GNSS radio occultations,'' \emph{Royal Society Open Science}, \textbf{7}(200320):15pp, 2020. DOI \texttt{10.1098/rsos.200320}\\\hfill{Accessed 22 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\bibitem{ref-27}
Joon-myoung K,  Younghoon C,  Ki-Hyun J,  Soohyun C,  Kyung-Hee K,  Seung D B,  Soomin J,  Jinsik P and  Byung-Hee O, ``A deep learning algorithm to detect anaemia with ECGs: a retrospective, multicentre study,'' \emph{Lancet Digital Health}, \textbf{2}(7):9pp, 2020. DOI \texttt{10.1016/S2589-7500(20)30108-4}\\\hfill{Accessed 24 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\bibitem{ref-28}
Zhu H,  Cheng C,  Yin H,  Li X,  Zuo P,  Ding J,  Lin F,  Wang J,  Zhou B,  Li Y,  Hu S,  Xiong Y,  Wang B,  Wan G,  Yang X and  Yuan Y, ``Automatic multilabel electrocardiogram diagnosis of heart rhythm or conduction abnormalities with deep learning: a cohort study,'' \emph{Lancet Digital Health}, \textbf{2}(7):9pp, 2020. DOI \texttt{10.1016/S2589-7500(20)30107-2}\\\hfill{Accessed 24 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\maprepo{manifold-ga}\bibitem{ref-29}
Fung R,  Villar J,  Dashti A,  Ismail LC,  Staines-Urias E,  Ohuma EO,  Salomon LJ,  Victora CG,  Barros FC,  Lambert A,  Carvalho M,  Jaffer Y A,  Noble JA,  Gravett MG,  Purwar M,  Pang R,  Bertino E,  Munim S,  Min AM,  McGready R,  Norris SA,  Bhutta ZA,  Kennedy SH,  Papageorghiou AT and  Ourmazd A, ``Achieving accurate estimates of fetal gestational age and personalised predictions of fetal growth based on data from an international prospective cohort study: a population-based machine learning study,'' \emph{Lancet Digital Health}, \textbf{2}(7):7pp, 2020. DOI \texttt{10.1016/S2589-7500(20)30131-X} {Code \url{github.com/ki-analysis/manifold-ga}}\\\hfill{Accessed 24 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\bibitem{ref-30}
Sabanayagam C,  Xu D,  Ting DSW,  Nusinovici S,  Banu R,  Hamzah H,  Lim C,  Tham Y-C,  Cheung CY,  Tai ES,  Wang XY,  Jonas JB,   Cheng C-Y,  Lee ML,  Hsu W and  Wong TY, ``A deep learning algorithm to detect chronic kidney disease from retinal photographs in community-based populations,'' \emph{Lancet Digital Health}, \textbf{2}(7):7pp, 2020. DOI \texttt{10.1016/S2589-7500(20)30063-7}\\\hfill{Accessed 24 July 2020.}\ {Double-checked 26 January 2021}.}\bibskip

\vbox{\maprepo{blast-ct}\bibitem{ref-31}
Monteiro M,  Newcombe VF,  Mathieu F,  Adatia K,  Kamnitsas K,  Ferrante E,  Das T,  Whitehouse D,  Rueckert D,  Menon DK and  Glocker B, ``Multiclass semantic segmentation and quantification of traumatic brain injury lesions on head CT using deep learning: an algorithm development and multicentre validation study,'' \emph{Lancet Digital Health}, \textbf{2}(7):8pp, 2020. DOI \texttt{10.1016/S2589-7500(20)30085-6} {Code \url{github.com/biomedia-mira/blast-ct}}\\\hfill{Accessed 24 July 2020.}\ {Double-checked 27 January 2021}.}\bibskip

\vbox{\bibitem{ref-32}
Liu K-L,  Wu T,  Chen P-T,  Tsai Y M,  Roth H,  Wu M-S,  Liao W-C and  Wang W, ``Deep learning to distinguish pancreatic cancer tissue from non-cancerous pancreatic tissue: a retrospective study with cross-racial external validation,'' \emph{Lancet Digital Health}, \textbf{2}(7):10pp, 2020. DOI \texttt{10.1016/S2589-7500(20)30078-9}\\\hfill{Accessed 24 July 2020.}\ {Double-checked 27 January 2021}.}\bibskip

% end expanding generated-supplementary-references.tex

\end{thebibliography}

\immediate\closeout\infofile
\immediate\closeout\contentsfile
\immediate\closeout\minicontentsfile

\end{document}  